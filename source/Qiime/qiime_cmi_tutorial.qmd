---
format:
  html:
    theme: cosmo
    toc: true
    toc-location: left
    embed-resources: true
bibliography: references.bib
csl: the-isme-journal.csl
engine: knitr
execute: 
  eval: false
---

# Notes to follow the QIIME CMI tutorial

**Notice**: 

- This tutorial was not written by myself but taken from [QIIME tutorial](https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/index.html). Additionally, the notes you find here were expended by copying from several spots in the QIIME documentation to explore things.
- The code was run on my personal computer (Windows, WSL2).
- If you follow the link for the tutorial, you will see that the tutorial is also available using the Galaxy interface and python API.

Other useful resources to check out:

-   [QIIME 2 view](https://view.qiime2.org/): web-based viewer for .qza and .qzv files
-   [QIIME forum](https://forum.qiime2.org/)
-   [QIIME2 docs](https://docs.qiime2.org/2023.7/). Notice, the tutorial runs on v2021.2, which we will use for now and later update to the newest QIIME version
-   [QIIME2 Library](https://library.qiime2.org/). Useful to check for new plugins/functionality
-   [Old QIIME tutorials](https://docs.qiime2.org/2021.2/tutorials/)
-   [NEW QIIME tutorials](https://docs.qiime2.org/2023.7/)

## Introductory notes

### Terminology

-   All files generated by QIIME 2 are either .qza or .qzv files, and these are simply zip files that store your data alongside some QIIME 2-specific metadata. You can unzip them with `unzip xxx.qza`

-   The .qza file extension is an abbreviation for QIIME Zipped Artifact, and the .qzv file extension is an abbreviation for QIIME Zipped Visualization. .qza files (which are often simply referred to as artifacts) are intermediary files in a QIIME 2 analysis, usually containing raw data of some sort.

-   Data produced by QIIME 2 exist as QIIME 2 **artifacts**. A QIIME 2 artifact contains data and metadata. The metadata describes things about the data, such as its type, format, and how it was generated (provenance). A QIIME 2 artifact typically has the .qza file extension when stored in a file. Since QIIME 2 works with artifacts instead of data files (e.g. FASTA files), you must create a QIIME 2 artifact by importing data.

-   **Visualizations** are another type of data generated by QIIME 2. When written to disk, visualization files typically have the .qzv file extension. Visualizations contain similar types of metadata as QIIME 2 artifacts, including provenance information. Similar to QIIME 2 artifacts, visualizations are standalone information that can be archived or shared with collaborators. Use https://view.qiime2.org to easily view QIIME 2 artifacts and visualizations files (generally .qza and .qzv files) without requiring a QIIME installation.

-   **Plugins** are software packages that can be developed by anyone and define actions, which are steps in an analysis workflow. The QIIME 2 team has developed several plugins for an initial end-to-end microbiome analysis pipeline, but third-party developers are encouraged to create their own plugins to provide additional analyses.

-   QIIME actions:

    -   A **method**, i.e.alpha-phylogenetic, accepts some combination of QIIME 2 artifacts and parameters as input, and produces one or more QIIME 2 artifacts (qza file) as output.
    -   A **visualizer** is similar to a method in that it accepts some combination of QIIME 2 artifacts and parameters as input and generate qzv files. In contrast to a method, a visualizer produces exactly one visualization as output. An example of a QIIME 2 visualizer is the beta-group-significance action in the q2-diversity plugin.
    -   A **pipeline** can generate one or more .qza and/or .qzv as output. Pipelines are special in that they're a type of action that can call other actions. They are often used by developers to define simplify common workflows so they can be run by users in a single step. For example, the core-metrics-phylogenetic action in the q2-diversity plugin is a Pipeline that runs both alpha-phylogenetic and beta-phylogenetic, as well as several other actions, in a single command.

-   Types used in QIIME 2:

    -   **File type**: the format of a file used to store some data. For example, newick is a file type that is used for storing phylogenetic trees.
    -   **Data type**: refer to how data is represented in a computer's memory (i.e., RAM) while it's actively in use.
    -   Every artifact generated by QIIME 2 has a **semantic type** associated with it. This is a representation of the meaning of the data. For example, two semantic types used in QIIME 2 are Phylogeny\[Rooted\] and Phylogeny\[Unrooted\], which are used to represent rooted and unrooted trees, respectively. QIIME 2 methods will describe what semantic types they take as input(s), and what semantic types they generate as output(s).

## Metadata

Find out more also [here](https://docs.qiime2.org/2023.7/tutorials/metadata/).

-   Metadata:

    -   **Sample metadata** may include technical details, such as the DNA barcodes that were used for each sample in a multiplexed sequencing run, or descriptions of the samples, such as which subject, time point, and body site each sample came from
    -   **Feature metadata** is often a feature annotation, such as the taxonomy assigned to an amplicon sequence variant (ASV).
    -   QIIME 2 does not place restrictions on what types of metadata are expected to be present; there are no enforced "metadata standards".
    -   the [MIxS and MIMARKS standards](https://www.nature.com/articles/nbt.1823) [@yilmaz2011] provide recommendations for microbiome studies and may be helpful in determining what information to collect in your study. If you plan to deposit your data in a data archive (e.g. ENA or Qiita), it is also important to determine the types of metadata expected by that resource.
    -   In QIIME 2, we always refer to these files as metadata files, but they are conceptually the same thing as QIIME 1 mapping files. QIIME 2 metadata files are backwards-compatible with QIIME 1 mapping files, meaning that you can use existing QIIME 1 mapping files in QIIME 2 without needing to make modifications to the file.

### Formatting requirements

-   Usually provided as TSV file (.tsv or .txt file extension) that provides data in form of rows and columns
-   First row = non-comment, non-empty **column headers** containing a unique identifier for each metadata entry
-   Rows whose first cell begins with the pound sign (#) are interpreted as comments and may appear anywhere in the file. Comment rows are ignored by QIIME 2 and are for informational purposes only. Inline comments (i.e., comments that begin part-way through a row or at the end of a row) are not supported.
-   Empty rows (e.g. blank lines or rows consisting solely of empty cells) may appear anywhere in the file and are ignored.
-   **Column 1**: **identifier (ID)** column. This column defines the sample or feature IDs associated with your study. It is not recommended to mix sample and feature IDs in a single metadata file; keep sample and feature metadata stored in separate files. The ID column name (also referred to as the ID column header) must be:
    -   Case-insenitive (i.e., uppercase or lowercase, or a mixing of the two, is allowed): id, sampleid, sample id, sample-id, featureid feature id, feature-id
    -   IDs may consist of any Unicode characters, with the exception that IDs must not start with the pound sign (#), as those rows would be interpreted as comments and ignored.
    -   IDs cannot be empty (i.e. they must consist of at least one character).
    -   IDs must be unique (exact string matching is performed to detect duplicates).
    -   At least one ID must be present in the file.
    -   IDs cannot be any of the reserved ID headers listed above.
-   The ID column is the first column in the metadata file, and can optionally be followed by additional columns defining metadata associated with each sample or feature ID. Metadata files are not required to have additional metadata columns, so a file containing only an ID column is a valid QIIME 2 metadata file.
-   The contents of a metadata file following the ID column and header row (excluding comments and empty lines) are referred to as the **metadata values**. A single metadata value, defined by an (ID, column) pair, is referred to as a **cell**. The following rules apply to metadata values and cells:
    -   May consist of any Unicode characters.
    -   Empty cells represent missing data. Other values such as NA are not interpreted as missing data; only the empty cell is recognized as "missing". Note that cells consisting solely of whitespace characters are also interpreted as missing data
    -   If any cell in the metadata contains leading or trailing whitespace characters (e.g. spaces, tabs), those characters will be ignored when the file is loaded.

Recommendations for identifiers:

-   Identifiers should be 36 characters long or less.
-   Identifiers should contain only ASCII alphanumeric characters (i.e. in the range of \[a-z\], \[A-Z\], or \[0-9\]), the period (.) character, or the dash (-) character.
-   Note that some bioinformatics tools may have more restrictive requirements on identifiers than the recommendations that are outlined here. For example, Illumina sample sheet identifiers cannot have . characters, while we do include those in our set of recommended characters
-   \[cual-id\] (https://github.com/johnchase/cual-id) can be used to help create identifiers and the associated paper also includes a discussion on how to choose identifiers [@chase2015].

Column types:

-   QIIME 2 currently supports *categorical* and *numeric* metadata columns and will automatically attempt to infer the type of each metadata column

-   QIIME 2 supports an **optional comment directive** to allow users to explicitly state a column's type.

-   The comment directive must appear directly below the header row. The value in the ID column in this row must be #q2:types to indicate the row is a comment directive. Subsequent cells in this row may contain the values categorical or numeric (both case-insensitive). The empty cell is also supported if you do not wish to assign a type to a column

Metadata validation:

-   QIIME 2 will automatically validate a metadata file anytime it is used. Loading your metadata in QIIME 2 will typically present only a single error at a time, which can make identifying and resolving validation issues cumbersome, especially if there are many issues with the metadata.

-   Sample and feature metadata files stored in Google Sheets can additionally be validated using [Keemei](https://keemei.qiime2.org/) [@rideout2016]

### The study

-   This tutorial focuses on data reused a [Compilation of longitudinal microbiota data and hospitalome from hematopoietic cell transplantation patients](https://www.nature.com/articles/s41597-021-00860-8) [@liao2021]

### Getting help

```{bash}
#find out what plugins are installed
qiime --help

#get help for a plugin of interest
qiime diversity --help

#get help for an action in a plugin
qiime diversity alpha-phylogenetic --help
```

## Setup

### QIIME installation

Run this if needed. If you are not using mamba yet, replace mamba with conda to use this as an alternative installer.

```{bash}
wget https://data.qiime2.org/distro/core/qiime2-2023.7-py38-linux-conda.yml
mamba env create -n qiime2-2023.7 --file qiime2-2023.7-py38-linux-conda.yml
#mamba activate qiime2-2023.7
```


### Set the working environment

```{bash}
#set wdir
wdir="/mnt/c/Users/ndmic/WorkingDir/UvA/Tutorials/QIIME/qiime_cmi_tutorial"
cd $wdir 

#activate QIIME environment 
mamba activate qiime2-2023.7
```

## Download data

```{bash}
mkdir data
mkdir visualizations

#download metadata table
wget \
  -O 'sample-metadata.tsv' \
  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/020-tutorial-upstream/020-metadata/sample-metadata.tsv'

#prepare metadata for qiime view 
qiime metadata tabulate \
  --m-input-file sample-metadata.tsv \
  --o-visualization visualizations/metadata-summ-1.qzv

#download sequencing data (already demultiplexed)
wget \
  -O 'data_to_import.zip' \
  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/020-tutorial-upstream/030-importing/data_to_import.zip'

unzip -d data_to_import data_to_import.zip

rm data_to_import.zip
```

## `qiime tools import`: Import data into QIIME

```{bash}
#import data into qiime
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-format CasavaOneEightSingleLanePerSampleDirFmt \
  --input-path data_to_import \
  --output-path demultiplexed-sequences.qza

#generate a summary of the imported data
qiime demux summarize \
  --i-data demultiplexed-sequences.qza \
  --o-visualization visualizations/demultiplexed-sequences-summ.qzv
```

**qiime demux**: supports demultiplexing of single-end and paired-end sequence reads and visualization of sequence quality information.

## Demultiplexing

If you have reads from multiple samples in the same file, you'll need to demultiplex your sequences.

If your barcodes are still in your sequences, you can use functions from the cutadapt plugin. The cutadapt demux-single method looks for barcode sequences at the beginning of your reads (5' end) with a certain error tolerance, removes them, and returns sequence data separated by each sample. The QIIME 2 forum has a [tutorial on various functions available in cutadapt](https://forum.qiime2.org/t/demultiplexing-and-trimming-adapters-from-reads-with-q2-cutadapt/2313), including demultiplexing. You can learn more about how cutadapt works under the hood by reading their [documentation](https://cutadapt.readthedocs.io/en/stable/index.html).

Note: Currently q2-demux and q2-cutadapt do not support demultiplexing dual-barcoded paired-end sequences, but only can demultiplex with barcodes in the forward reads. So for the time being, this type of demultiplexing needs to be done outside of QIIME 2 using other tools, for example bcl2fastq.

Notice: This is not applicable for this tutorial and you only will find some relevant notes here.

There are two plugins to check out:

-   [q2-demux](https://docs.qiime2.org/2023.7/plugins/available/demux/)
-   [cutadapt](https://docs.qiime2.org/2023.7/plugins/available/cutadapt/)

## Merging reads

Whether or not you need to merge reads depends on how you plan to cluster or denoise your sequences into amplicon sequence variants (ASVs) or operational taxonomic units (OTUs). If you plan to use deblur or OTU clustering methods next, join your sequences now. If you plan to use dada2 to denoise your sequences, do not merge --- dada2 performs read merging automatically after denoising each sequence.

If you need to merge your reads, you can use the QIIME 2 q2-vsearch plugin with the merge-pairs method.

Notice: This is not applicable for this tutorial and you only will find some relevant notes here.

## Removing non-biological sequences

If your data contains any non-biological sequences (e.g. primers, sequencing adapters, PCR spacers, etc), you should remove these.

The q2-cutadapt plugin has comprehensive methods for removing non-biological sequences from paired-end or single-end data.

If you're going to use DADA2 to denoise your sequences, you can remove biological sequences at the same time as you call the denoising function. All of DADA2's denoise fuctions have some sort of --p-trim parameter you can specify to remove base pairs from the 5' end of your reads. (Deblur does not have this functionality yet.)

## Denoising and clustering

The names for these steps are very descriptive:

1.  We denoise our sequences to remove and/or correct noisy reads.
2.  We dereplicate our sequences to reduce repetition and file size/memory requirements in downstream steps.
3.  We cluster sequences to collapse similar sequences (e.g., those that are ≥ 97% similar to each other) into single replicate sequences. This process, also known as **OTU picking**, was once a common procedure, used to simultaneously dereplicate but also perform a sort of quick-and-dirty denoising procedure (to capture stochastic sequencing and PCR errors, which should be rare and similar to more abundant centroid sequences). **Use denoising methods instead if you can.**

The denoising methods currently available in QIIME 2 include DADA2 and Deblur. Note that deblur (and also vsearch dereplicate-sequences) should be preceded by basic quality-score-based filtering, but this is unnecessary for dada2. Both Deblur and DADA2 contain internal chimera checking methods and abundance filtering, so additional filtering should not be necessary following these methods.

To put it simply, these methods filter out noisy sequences, correct errors in marginal sequences (in the case of DADA2), remove chimeric sequences, remove singletons, join denoised paired-end reads (in the case of DADA2), and then dereplicate those sequences.

### The feature table

The final products of all denoising and clustering methods/workflows are a **FeatureTable\[Frequency\]** (feature table) artifact and a **FeatureData\[Sequence\]** (representative sequences) artifact. These are two of the most important artifacts in an amplicon sequencing workflow, and are used for many downstream analyses.

Many operations on these tables can be performed with [q2-feature-table](https://docs.qiime2.org/2023.7/plugins/available/feature-table/).

Want to see which sequences are associated with each feature ID? Use qiime metadata tabulate with your FeatureData\[Sequence\] artifact as input.

### Dada 2 workflow

Quality control or denoising of the sequence data will be performed with DADA2 [@callahan2016]. DADA2 is an model-based approach for correcting amplicon errors without constructing OTUs. Can be applied to every gene of interest and is not limited to the 16S.

The DADA2 algorithm makes use of a parametric error model (err) and every amplicon dataset has a different set of error rates. The learnErrors method learns this error model from the data, by alternating estimation of the error rates and inference of sample composition until they converge on a jointly consistent solution. As in many machine-learning problems, the algorithm must begin with an initial guess, for which the maximum possible error rates in this data are used (the error rates if only the most abundant sequence is correct and all the rest are errors).

Also check out [this tutorial](https://benjjneb.github.io/dada2/tutorial.html) for using DADA2. One important parameter to check is `truncLen` to trim low quality read ends. Also check out [this paper](https://academic.oup.com/bioinformatics/article/31/21/3476/194979?login=false) discussing quality filtering [@edgar2015].

In QIIME the denoise_paired action in the q2-dada2 plugin. This performs quality filtering, chimera checking, and paired- end read joining.

The denoise_paired action requires a few parameters that you'll set based on the sequence quality score plots that you previously generated in the summary of the demultiplex reads. You should review those plots and identify where the quality begins to decrease, and use that information to set the `trunc_len_*` parameters. You'll set that for both the forward and reverse reads using the `trunc_len_f` and `trunc_len_r` parameters, respectively. If you notice a region of lower quality in the beginning of the forward and/or reverse reads, you can optionally trim bases from the beginning of the reads using the trim_left_f and trim_left_r parameters for the forward and reverse reads, respectively. Your reads must still overlap after truncation in order to merge them later!

Some thoughts on this:

-   Reviewing the data we notice that the twenty-fifth percentile quality score drops below 30 at position 204 in the forward reads and 205 in the reverse reads. We chose to use those values for the required truncation lengths. This truncates the 3'/5' end of the of the input sequences. Reads that are shorter than this value will be discarded. After this parameter is applied there must still be at least a 12 nucleotide overlap between the forward and reverse reads.
-   Since the first base of the reverse reads is slightly lower than those that follow, I choose to trim that first base in the reverse reads, but apply no trimming to the forward reads. This trimming is probably unnecessary here, but is useful here for illustrating how this works.
-   [Figaro](https://github.com/Zymo-Research/figaro#figaro) is a tool to automatically choose the trunc_len
-   **Chimeric sequences** are identified if they can be exactly reconstructed by combining a left-segment and a right-segment from two more abundant "parent" sequences. Most of your reads should remain after chimera removal (it is not uncommon for a majority of sequence variants to be removed though). If most of your reads were removed as chimeric, upstream processing may need to be revisited. In almost all cases this is caused by primer sequences with ambiguous nucleotides that were not removed prior to running DADA2

Desired overlap length

-   Often between 10 and 20 for most applications.
-   DADA2 often recommends 20
-   Remember: longer overlaps means more 3' end must be kept at a cost of decreased overall sequence quality

Other parameters:

-   `--p-max-ee-f/r {number}`: Forward reads with number of expected errors higher than this value will be discarded. \[default: 2.0\]. If you want to speed up downstream computation, consider tightening maxEE. If too few reads are passing the filter, consider relaxing maxEE, perhaps especially on the reverse reads (eg. maxEE=c(2,5))
-   `--p-trunc-q {integeer}`: Reads are truncated at the first instance of a quality score less than or equal to this value. If the resulting read is then shorter than `trunc-len-f`or `trunc-len-r` (depending on the direction of the read) it is discarded. \[default: 2\]
-   `--p-min-overlap {INTEGER}`: The minimum length of the overlap required for merging the forward and reverse reads. \[default: 12\]
-   `--p-pooling-method` {TEXT Choices('independent', 'pseudo')}: he method used to pool samples for denoising. By default, the dada function processes each sample independently. However, pooling information across samples can increase sensitivity to sequence variants that may be present at very low frequencies in multiple samples. "independent": Samples are denoised indpendently. "pseudo": The pseudo-pooling method is used to approximate pooling of samples. In short, samples are denoised independently once, ASVs detected in at least 2 samples are recorded, and samples are denoised independently a second time, but this time with prior knowledge of the recorded ASVs and thus higher sensitivity to those ASVs. \[default: 'independent'\]
-   `--p-chimera-method` {TEXT Choices('consensus', 'none', 'pooled')}: The method used to remove chimeras. "none": No chimera removal is performed. "pooled": All reads are pooled prior to chimera detection. "consensus": Chimeras are detected in samples individually, and sequences found chimeric in a sufficient fraction of samples are removed. \[default: 'consensus'\]
-   `--p-n-threads` {INTEGER}: default 1

Outputs:

-   The feature table describes which amplicon sequence variants (ASVs) were observed in which samples, and how many times each ASV was observed in each sample.
-   The feature data in this case is the sequence that defines each ASV. Generate and explore the summaries of each of these files.
-   **Sanity check**: in stats-dada2 check that outside of filtering, there should no step in which a majority of reads are lost. If a majority of reads failed to merge, you may need to revisit the truncLen parameter used in the filtering step and make sure that the truncated reads span your amplicon. If a majority of reads were removed as chimeric, you may need to revisit the removal of primers, as the ambiguous nucleotides in unremoved primers interfere with chimera identification
-   Sequences that are much longer or shorter than expected may be the result of non-specific priming. You could consider removing those sequences from the asv table.

```{bash}
#denoise data
qiime dada2 denoise-paired \
  --i-demultiplexed-seqs demultiplexed-sequences.qza \
  --p-trunc-len-f 204 \
  --p-trim-left-r 1 \
  --p-trunc-len-r 205 \
  --o-representative-sequences asv-sequences-0.qza \
  --o-table feature-table-0.qza \
  --o-denoising-stats dada2-stats.qza

#generate summaries
qiime feature-table summarize \
  --i-table feature-table-0.qza \
  --m-sample-metadata-file sample-metadata.tsv \
  --o-visualization visualizations/feature-table-0-summ.qzv

qiime feature-table tabulate-seqs \
  --i-data asv-sequences-0.qza \
  --o-visualization visualizations/asv-sequences-0-summ.qzv

qiime metadata tabulate \
  --m-input-file dada2-stats.qza \
  --o-visualization visualizations/stats-dada2.qzv
```

Outputs:

-   ASV table,
-   the representative sequences,
-   statistics on the procedure

## Filtering the feature table

We'll next obtain a much larger feature table representing all of the samples included in the study dataset. These would take too much time to denoise in this course, so we'll start with the feature table, sequences, and metadata provided by the authors and filter to samples that we'll use for our analyses.

A full description can be foun on the [QIIME website](https://docs.qiime2.org/2023.7/tutorials/filtering/#filtering-data)

```{bash}
#cleanup first dataset
mkdir upstream_tutorial
mv *qza upstream_tutorial/

#get the data
wget \
  -O 'feature-table.qza' \
  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/030-tutorial-downstream/010-filtering/feature-table.qza'

wget \
  -O 'rep-seqs.qza' \
  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/030-tutorial-downstream/010-filtering/rep-seqs.qza'

#summarize table
qiime feature-table summarize \
  --i-table feature-table.qza \
  --m-sample-metadata-file sample-metadata.tsv \
  --o-visualization visualizations/feature-table-summ.qzv

qiime feature-table tabulate-seqs \
  --i-data rep-seqs.qza \
  --o-visualization visualizations/rep-seqs-summ.qzv

```

Output explanation:

-   A **feature** is essentially any unit of observation, e.g., an OTU, a sequence variant, a gene, a metabolite, etc, and a feature table is a matrix of sample X feature abundances (the number of times each feature was observed in each sample).
-   minimum frequency is 5342 - if you click the "Interactive Sample Detail" tab and scroll to the bottom, you will see that the sample with the lowest feature frequency has 5342 observations. Similarly, the sample with the highest frequency of features has 193491 total observations - meaning that many/most features were seen more than once.
-   mean frequency of features (881)? Does it mean that one feature is found in average 881 times throughout all the samples

### Downsample the feature table

```{bash}
#filtering
qiime feature-table filter-samples \
  --i-table feature-table.qza \
  --m-metadata-file sample-metadata.tsv \
  --p-where 'autoFmtGroup IS NOT NULL' \
  --o-filtered-table autofmt-table.qza

#summarize
qiime feature-table summarize \
  --i-table autofmt-table.qza \
  --m-sample-metadata-file sample-metadata.tsv \
  --o-visualization visualizations/autofmt-table-summ.qzv

#filter time window
qiime feature-table filter-samples \
  --i-table autofmt-table.qza \
  --m-metadata-file sample-metadata.tsv \
  --p-where 'DayRelativeToNearestHCT BETWEEN -10 AND 70' \
  --o-filtered-table filtered-table-1.qza

#filter features from the feature table if they don’t occur in at least two samples
#done to reduce runtime (so optional)
qiime feature-table filter-features \
  --i-table filtered-table-1.qza \
  --p-min-samples 2 \
  --o-filtered-table filtered-table-2.qza

#summarize
qiime feature-table summarize \
  --i-table filtered-table-2.qza \
  --m-sample-metadata-file sample-metadata.tsv \
  --o-visualization visualizations/filtered-table-2-summ.qzv

```

Options for `qiime feature-table filter-samples`:

-   Any features with a frequency of zero after sample filtering will also be removed.
-   `--p-min-frequency` {INTEGER} The minimum total frequency that a sample must have to be retained. \[default: 0\]
-   `--p-max-frequency` {INTEGER} The maximum total frequency that a sample can have to be retained. If no value is provided this will default to infinity (i.e., no maximum frequency filter will be applied). \[optional\]
-   `--p-min-features` {INTEGER} The minimum number of features that a sample must have to be retained. \[default: 0\]
-   `--p-max-features` {INTEGER}
-   `--m-metadata-file` METADATA... (multiple Sample metadata used with `where` parameter when arguments will selecting samples to retain, or with `exclude-ids` when be merged) selecting samples to discard. \[optional\]
-   `--p-where` {TEXT} SQLite WHERE clause specifying sample metadata criteria that must be met to be included in the filtered feature table. If not provided, all samples in `metadata` that are also in the feature table will be retained. \[optional\] `--p-exclude-ids` / `--p-no-exclude-ids` If true, the samples selected by `metadata` or `where` parameters will be excluded from the filtered table instead of being retained. \[default: False\] `--p-filter-empty-features` / `--p-no-filter-empty-features` If true, features which are not present in any retained samples are dropped. \[default: True\]
-   `--p-min-samples` {number}: filter features from a table contingent on the number of samples they're observed in.
-   `--p-min-features` {number}: filter samples that contain only a few features

We can also also filter tables by lists:

```{bash}
#create imaginary list of ids to keep
echo L1S8 >> samples-to-keep.tsv

#filter 
qiime feature-table filter-samples \
  --i-table table.qza \
  --m-metadata-file samples-to-keep.tsv \
  --o-filtered-table id-filtered-table.qza
```

Some examples using where:

-   --p-where "\[subject\]='subject-1'"\
-   --p-where "\[body-site\] IN ('left palm', 'right palm')"\
-   --p-where "\[subject\]='subject-1' AND \[body-site\]='gut'"\
-   --p-where "\[body-site\]='gut' OR \[reported-antibiotic-usage\]='Yes'"\
-   --p-where "\[subject\]='subject-1' AND NOT \[body-site\]='gut'"\

### Filter features from sequence data

```{bash}
qiime feature-table filter-seqs \
  --i-data rep-seqs.qza \
  --i-table filtered-table-2.qza \
  --o-filtered-data filtered-sequences-1.qza
```

## Taxonomic annotations

To identify the organisms in a sample it is usually not enough using the closest alignment --- because other sequences that are equally close matches or nearly as close may have different taxonomic annotations. So we use taxonomy classifiers to determine the closest taxonomic affiliation with some degree of confidence or consensus (which may not be a species name if one cannot be predicted with certainty!), based on alignment, k-mer frequencies, etc.

q2-feature-classifier contains three different classification methods: - classify-consensus-blast and classify-consensus-vsearch are both alignment-based methods that find a consensus assignment across N top hits. These methods take reference database FeatureData\[Taxonomy\] and FeatureData\[Sequence\] files directly, and do not need to be pre-trained - Machine-learning-based classification methods are available through classify-sklearn, and theoretically can apply any of the classification methods available in scikit-learn. These classifiers must be trained, e.g., to learn which features best distinguish each taxonomic group, adding an additional step to the classification process. Classifier training is reference database- and marker-gene-specific and only needs to happen once per marker-gene/reference database combination; that classifier may then be re-used as many times as you like without needing to re-train! - Most users do not even need to follow that tutorial and perform that training step, because the lovely QIIME 2 developers provide several [pre-trained classifiers](https://docs.qiime2.org/2023.7/data-resources/) for public use.

In general classify-sklearn with a Naive Bayes classifier can slightly outperform other methods we've tested based on several criteria for classification of 16S rRNA gene and fungal ITS sequences. It can be more difficult and frustrating for some users, however, since it requires that additional training step. That training step can be memory intensive, becoming a barrier for some users who are unable to use the pre-trained classifiers.

In the example below we use a pre-trained Naive Bayes taxonomic classifier. This particular classifier was trained on the Greengenes 13-8 database, where sequences were trimmed to represent only the region between the 515F / 806R primers.

Check out the [Qiime info page](https://docs.qiime2.org/2023.7/tutorials/feature-classifier/) for other classifiers.

Notes:

-   Taxonomic classifiers perform best when they are trained based on your specific sample preparation and sequencing parameters, including the primers that were used for amplification and the length of your sequence reads. Therefore in general you should follow the instructions in [Training feature classifiers with q2-feature-classifier](https://docs.qiime2.org/2023.7/tutorials/feature-classifier/) to train your own taxonomic classifiers (for example, from the marker gene reference databases below).
-   Greengenes2 has succeeded Greengenes 13_8
-   The Silva classifiers provided here include species-level taxonomy. While Silva annotations do include species, Silva does not curate the species-level taxonomy so this information may be unreliable.
-   Check out [this study](https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-018-0470-z) to learn more about QIIMEs feature classifier [@bokulich2018].
-   Check out [this study](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009581) discussing reproducible sequence taxonomy reference database management [@ii2021].
-   Check out [this study](https://www.nature.com/articles/s41467-019-12669-6) about incorporating environment-specific taxonomic abundance information in taxonomic classifiers [@kaehler2019].

### Link ASV to taxonomy

```{bash}
#get classifier
wget \
  -O 'gg-13-8-99-nb-classifier.qza' \
  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/030-tutorial-downstream/020-taxonomy/gg-13-8-99-nb-classifier.qza'

#assign taxonomic info to ASV sequences
qiime feature-classifier classify-sklearn \
  --i-classifier gg-13-8-99-nb-classifier.qza \
  --i-reads filtered-sequences-1.qza \
  --o-classification taxonomy.qza

#generate summary
qiime metadata tabulate \
  --m-input-file taxonomy.qza \
  --o-visualization visualizations/taxonomy.qzv
```

### Filter based on taxonomy

A common step in 16S analysis is to remove sequences from an analysis that aren't assigned to a phylum. In a human microbiome study such as this, these may for example represent reads of human genome sequence that were unintentionally sequences.

Here, we:

-   specify with the include paramater that an annotation must contain the text p\_\_, which in the Greengenes taxonomy is the prefix for all phylum-level taxonomy assignments. Taxonomic labels that don't contain p\_\_ therefore were maximally assigned to the domain (i.e., kingdom) level.
-   remove features that are annotated with p\_\_; (which means that no named phylum was assigned to the feature), as well as annotations containing Chloroplast or Mitochondria (i.e., organelle 16S sequences).

```{bash}
qiime taxa filter-table \
  --i-table filtered-table-2.qza \
  --i-taxonomy taxonomy.qza \
  --p-mode contains \
  --p-include p__ \
  --p-exclude 'p__;,Chloroplast,Mitochondria' \
  --o-filtered-table filtered-table-3.qza
```

Other options:

Filter by taxonomy:

```{bash}
qiime taxa filter-table \
  --i-table table.qza \
  --i-taxonomy taxonomy.qza \
  --p-exclude mitochondria \
  --o-filtered-table table-no-mitochondria.qza

qiime taxa filter-table \
  --i-table table.qza \
  --i-taxonomy taxonomy.qza \
  --p-exclude mitochondria,chloroplast \
  --o-filtered-table table-no-mitochondria-no-chloroplast.qza

qiime taxa filter-table \
  --i-table table.qza \
  --i-taxonomy taxonomy.qza \
  --p-include p__ \
  --o-filtered-table table-with-phyla.qza

qiime taxa filter-table \
  --i-table table.qza \
  --i-taxonomy taxonomy.qza \
  --p-include p__ \
  --p-exclude mitochondria,chloroplast \
  --o-filtered-table table-with-phyla-no-mitochondria-no-chloroplast.qza

qiime taxa filter-table \
  --i-table table.qza \
  --i-taxonomy taxonomy.qza \
  --p-mode exact \
  --p-exclude "k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rickettsiales; f__mitochondria" \
  --o-filtered-table table-no-mitochondria-exact.qza
```

We can also filter our sequences:

```{bash}
qiime taxa filter-seqs \
  --i-sequences sequences.qza \
  --i-taxonomy taxonomy.qza \
  --p-include p__ \
  --p-exclude mitochondria,chloroplast \
  --o-filtered-sequences sequences-with-phyla-no-mitochondria-no-chloroplast.qza
```

### Filtering samples with low sequence counts

You may have noticed when looking at feature table summaries earlier that some of the samples contained very few ASV sequences. These often represent samples which didn't amplify or sequence well, and when we start visualizing our data low numbers of sequences can cause misleading results, because the observed composition of the sample may not be reflective of the sample's actual composition. For this reason it can be helpful to exclude samples with low ASV sequence counts from our samples. Here, we'll filter out samples from which we have obtained fewer than 10,000 sequences.

```{bash}
qiime feature-table filter-samples \
  --i-table filtered-table-3.qza \
  --p-min-frequency 10000 \
  --o-filtered-table filtered-table-4.qza

#summarize data
qiime feature-table summarize \
  --i-table filtered-table-4.qza \
  --m-sample-metadata-file sample-metadata.tsv \
  --o-visualization visualizations/filtered-table-4-summ.qzv
```

### Filtering our sequence representatives

```{bash}
qiime feature-table filter-seqs \
  --i-data rep-seqs.qza \
  --i-table filtered-table-4.qza \
  --o-filtered-data filtered-sequences-2.qza
```

## Generate taxonomic composition barplots

```{bash}
qiime taxa barplot \
  --i-table filtered-table-4.qza \
  --i-taxonomy taxonomy.qza \
  --m-metadata-file sample-metadata.tsv \
  --o-visualization visualizations/taxa-bar-plots-1.qzv
```

Notice: We can also generate heatmaps with `feature-table heatmap`

## Phylogenetic tree construction

### Basics

One advantage of pipelines is that they combine ordered sets of commonly used commands, into one condensed simple command. To keep these "convenience" pipelines easy to use, it is quite common to only expose a few options to the user. That is, most of the commands executed via pipelines are often configured to use default option settings. However, options that are deemed important enough for the user to consider setting, are made available. The options exposed via a given pipeline will largely depend upon what it is doing. Pipelines are also a great way for new users to get started, as it helps to lay a foundation of good practices in setting up standard operating procedures.

Rather than run one or more of the following QIIME 2 commands listed below:

```         
qiime alignment mafft ...

qiime alignment mask ...

qiime phylogeny fasttree ...

qiime phylogeny midpoint-root ...
```

We can make use of the pipeline align-to-tree-mafft-fasttree to automate the above four steps in one go. Here is the description taken from the pipeline help doc:

More details can be found in the [QIIME docs](https://docs.qiime2.org/2023.7/tutorials/phylogeny/).

In general there are two approaches:

1.  A reference-based fragment insertion approach. Which, is likely the ideal choice. Especially, if your reference phylogeny (and associated representative sequences) encompass neighboring relatives of which your sequences can be reliably inserted. Any sequences that do not match well enough to the reference are not inserted. For example, this approach may not work well if your data contain sequences that are not well represented within your reference phylogeny (e.g. missing clades, etc.). For more information, check out these great [fragment insertion examples](https://library.qiime2.org/plugins/q2-fragment-insertion/16/).
2.  A de novo approach. Marker genes that can be globally aligned across divergent taxa, are usually amenable to sequence alignment and phylogenetic investigation through this approach. Be mindful of the length of your sequences when constructing a de novo phylogeny, short reads many not have enough phylogenetic information to capture a meaningful phylogeny.

### Runing the Qiime pipeline

```{bash}
qiime phylogeny align-to-tree-mafft-fasttree \
  --i-sequences filtered-sequences-2.qza \
  --output-dir phylogeny-align-to-tree-mafft-fasttree
```

The final unrooted phylogenetic tree will be used for analyses that we perform next - specifically for computing phylogenetically aware diversity metrics. While output artifacts will be available for each of these steps, we'll only use the rooted phylogenetic tree later.

Notice:

-   For an easy and direct way to view your tree.qza files, upload them to iTOL. Here, you can interactively view and manipulate your phylogeny. Even better, while viewing the tree topology in "Normal mode", you can drag and drop your associated alignment.qza (the one you used to build the phylogeny) or a relevent taxonomy.qza file onto the iTOL tree visualization. This will allow you to directly view the sequence alignment or taxonomy alongside the phylogeny

Methods in `qiime phylogeny`:

-   align-to-tree-mafft-iqtree
-   iqtree Construct a phylogenetic tree with IQ-TREE.
-   iqtree-ultrafast-bootstrap Construct a phylogenetic tree with IQ-TREE with bootstrap supports.
-   midpoint-root Midpoint root an unrooted phylogenetic tree.
-   robinson-foulds Calculate Robinson-Foulds distance between phylogenetic trees.


### Run things step by step

Before running iq-tree check out:

- qiime alignment mafft 
- qiime alignment mask 

Example to run the iqtree command with default settings and automatic model selection (MFP) is like so:

```{bash}
qiime phylogeny iqtree \
  --i-alignment masked-aligned-rep-seqs.qza \
  --o-tree iqt-tree.qza \
  --verbose
```

Example running iq-tree with single branch testing:

Single branch tests are commonly used as an alternative to the bootstrapping approach we've discussed above, as they are substantially faster and often recommended when constructing large phylogenies (e.g. \>10,000 taxa).

```{bash}
qiime phylogeny iqtree \
  --i-alignment masked-aligned-rep-seqs.qza \
  --p-alrt 1000 \
  --p-abayes \
  --p-lbp 1000 \
  --p-substitution-model 'GTR+I+G' \
  --o-tree iqt-sbt-tree.qza \
  --verbose
```

IQ-tree settings:

There are quite a few adjustable parameters available for iqtree that can be modified improve searches through "tree space" and prevent the search algorithms from getting stuck in local optima.

One particular best practice to aid in this regard, is to adjust the following parameters: --p-perturb-nni-strength and --p-stop-iter (each respectively maps to the `-pers` and `-nstop` flags of iqtree ).

In brief, the larger the value for NNI (nearest-neighbor interchange) perturbation, the larger the jumps in "tree space". This value should be set high enough to allow the search algorithm to avoid being trapped in local optima, but not to high that the search is haphazardly jumping around "tree space". One way of assessing this, is to do a few short trial runs using the `--verbose` flag. If you see that the likelihood values are jumping around to much, then lowering the value for `--p-perturb-nni-strength` may be warranted.

As for the stopping criteria, i.e. `--p-stop-iter`, the higher this value, the more thorough your search in "tree space". Be aware, increasing this value may also increase the run time. That is, the search will continue until it has sampled a number of trees, say 100 (default), without finding a better scoring tree. If a better tree is found, then the counter resets, and the search continues.

These two parameters deserve special consideration when a given data set contains many short sequences, quite common for microbiome survey data. We can modify our original command to include these extra parameters with the recommended modifications for short sequences, i.e. a lower value for perturbation strength (shorter reads do not contain as much phylogenetic information, thus we should limit how far we jump around in "tree space") and a larger number of stop iterations.

```{bash}
qiime phylogeny iqtree \
  --i-alignment masked-aligned-rep-seqs.qza \
  --p-perturb-nni-strength 0.2 \
  --p-stop-iter 200 \
  --p-n-cores 1 \
  --o-tree iqt-nnisi-fast-tree.qza \
  --verbose
```

iqtree-ultrafast-bootstrap:

we can also use IQ-TREE to evaluate how well our splits / bipartitions are supported within our phylogeny via the ultrafast bootstrap algorithm. Below, we'll apply the plugin's ultrafast bootstrap command: automatic model selection (MFP), perform 1000 bootstrap replicates (minimum required), set the same generally suggested parameters for constructing a phylogeny from short sequences, and automatically determine the optimal number of CPU cores to use:

```{bash}
qiime phylogeny iqtree-ultrafast-bootstrap \
  --i-alignment masked-aligned-rep-seqs.qza \
  --p-perturb-nni-strength 0.2 \
  --p-stop-iter 200 \
  --p-n-cores 1 \
  --o-tree iqt-nnisi-bootstrap-tree.qza \
  --verbose
```

## Identifying an even sampling depth for use in diversity metrics

### Notes on rarefication

Notice: Notes copied taken from [here](https://bioinformatics.ccr.cancer.gov/docs/qiime2/Lesson5/)

Feature tables are composed of sparse and [compositional data](https://www.frontiersin.org/articles/10.3389/fmicb.2017.02224/full) [@gloor2017]. Measuring microbial diversity using 16S rRNA sequencing is dependent on sequencing depth. By chance, a sample that is more deeply sequenced is more likely to exhibit greater diversity than a sample with a low sequencing depth.

Rarefaction is the process of subsampling reads without replacement to a defined sequencing depth, thereby creating a standardized library size across samples. Any sample with a total read count less than the defined sequencing depth used to rarefy will be discarded. Post-rarefaction all samples will have the same read depth. How do we determine the magic sequencing depth at which to rarefy? We typically use an alpha rarefaction curve.

As the sequencing depth increases, you recover more and more of the diversity observed in the data. At a certain point (read depth), diversity will stabilize, meaning the diversity in the data has been fully captured. This point of stabilization will result in the diversity measure of interest plateauing.

Notice:

-   You may want to skip rarefaction if library sizes are fairly even. Rarefaction is more beneficial when there is a greater than \~10x difference in library size [@weiss2017].
-   Rarefying is generally applied only to diversity analyses, and many of the methods in QIIME 2 will use plugin specific normalization methods

Some literature on the debate:

-   [Waste not, want not: why rarefying microbiome data is inadmissible](https://pubmed.ncbi.nlm.nih.gov/24699258/) [@mcmurdie2014]
-   [Normalization and microbial differential abundance strategies depend upon data characteristics](https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-017-0237-y) [@weiss2017]

### Alpha rarefaction plots

Alpha diversity is within sample diversity. When exploring alpha diversity, we are interested in the distribution of microbes within a sample or metadata category. This distribution not only includes the number of different organisms (**richness**) but also how evenly distributed these organisms are in terms of abundance (**evenness**).

Richness: High richness equals more ASVs or more phylogenetically dissimilar ASVs in the case of Faith's PD. Diversity increases as richness and evenness increase. Evenness: High values suggest more equal numbers between species.

[Here](http://scikit-bio.org/docs/latest/generated/skbio.diversity.alpha.html) is a description of the different metrices we can use. And check [here](https://www.davidzeleny.net/anadat-r/doku.php/en:div-ind) for a comparison of indices.

List of indices:

-   Shannon's diversity index (a quantitative measure of community richness)
-   Observed Features (a qualitative measure of community richness)
-   Faith's Phylogenetic Diversity (a qualitative measure of community richness that incorporates phylogenetic relationships between the features)
-   Evenness (or Pielou's Evenness; a measure of community evenness)

An important parameter that needs to be provided to this script is `--p-sampling-depth,` which is the even sampling (i.e. rarefaction) depth. Because most diversity metrics are sensitive to different sampling depths across different samples, this script will randomly subsample the counts from each sample to the value provided for this parameter. For example, if you provide `--p-sampling-depth 500`, this step will subsample the counts in each sample without replacement so that each sample in the resulting table has a total count of 500. If the total count for any sample(s) are smaller than this value, those samples will be dropped from the diversity analysis.

```{bash}
qiime diversity alpha-rarefaction \
  --i-table filtered-table-4.qza \
  --p-metrics shannon \
  --m-metadata-file sample-metadata.tsv \
  --p-max-depth 33000 \
  --o-visualization visualizations/shannon-rarefaction-plot.qzv
```

Note: The value that you provide for `--p-max-depth` should be determined by reviewing the "Frequency per sample" information presented in the table.qzv file that was created above. In general, choosing a value that is somewhere around the median frequency seems to work well, but you may want to increase that value if the lines in the resulting rarefaction plot don't appear to be leveling out, or decrease that value if you seem to be losing many of your samples due to low total frequencies closer to the minimum sampling depth than the maximum sampling depth.

Include phylo:

```{bash}
qiime diversity alpha-rarefaction \
  --i-table filtered-table-4.qza \
  --i-phylogeny phylogeny-align-to-tree-mafft-fasttree/rooted_tree.qza \
  --p-metrics faith_pd \
  --m-metadata-file sample-metadata.tsv \
  --p-max-depth 33000 \
  --o-visualization visualizations/faith-rarefaction-plot.qzv
```

Generate different metrics at the same time:

```{bash}
qiime diversity alpha-rarefaction \
  --i-table filtered-table-4.qza \
  --i-phylogeny phylogeny-align-to-tree-mafft-fasttree/rooted_tree.qza \
  --m-metadata-file sample-metadata.tsv \
  --p-max-depth 33000 \
  --o-visualization visualizations/alpha-rarefaction-plot.qzv 
```

**We can use this plot in combination with our feature table summary to decide at which depth we would like to rarefy. We need to choose a sequencing depth at which the diveristy in most of the samples has been captured and most of the samples have been retained.**

Choosing this value is tricky. We recommend making your choice by reviewing the information presented in the feature table summary file. Choose a value that is as high as possible (so you retain more sequences per sample) while excluding as few samples as possible.

## Computing diversity metrics

`core-metrics-phylogenetic`requires your feature table, your rooted phylogenetic tree, and your sample metadata as input. It additionally requires that you provide the sampling depth that this analysis will be performed at. Determining what value to provide for this parameter is often one of the most confusing steps of an analysis for users, and we therefore have devoted time to discussing this in the lectures and in the previous chapter. In the interest of retaining as many of the samples as possible, we'll set our sampling depth to 10,000 for this analysis.

```{bash}
qiime diversity core-metrics-phylogenetic \
  --i-phylogeny phylogeny-align-to-tree-mafft-fasttree/rooted_tree.qza \
  --i-table filtered-table-4.qza \
  --p-sampling-depth 10000 \
  --m-metadata-file sample-metadata.tsv \
  --output-dir diversity-core-metrics-phylogenetic
```

### Alpha diversity

The code below generates Alpha Diversity Boxplots as well as statistics based on the observed features. It allows us to explore the microbial composition of the samples in the context of the sample metadata.

```{bash}
qiime diversity alpha-group-significance \
  --i-alpha-diversity diversity-core-metrics-phylogenetic/observed_features_vector.qza \
  --m-metadata-file sample-metadata.tsv \
  --o-visualization visualizations/alpha-group-sig-obs-feats.qzv
```

The first thing to notice is the high variability in each individual's richness (PatientID). The centers and spreads of the individual distributions are likely to obscure other effects, so we will want to keep this in mind. Additionally, we have repeated measures of each individual, so we are violating independence assumptions when looking at other categories. (Kruskal-Wallis is a non-parameteric test, but like most tests, still requires samples to be independent.)

### Statistics

If continuous sample metadata columns (e.g., days-since-experiment-start) are correlated with alpha diversity, we can test for those associations here. If you're interested in performing those tests (for this data set, or for others), you can use the qiime diversity alpha-correlation command.

We can also analyze sample composition in the context of categorical metadata using PERMANOVA using the beta-group-significance command. The code below was taken from another test but would allow to test whether distances between samples within a group, such as samples from the same body site (e.g., gut), are more similar to each other then they are to samples from the other groups (e.g., tongue, left palm, and right palm). If you call this command with the `--p-pairwise` parameter, as we'll do here, it will also perform pairwise tests that will allow you to determine which specific pairs of groups (e.g., tongue and gut) differ from one another, if any. This command can be slow to run, especially when passing `--p-pairwise`, since it is based on permutation tests. So, unlike the previous commands, we'll run beta-group-significance on specific columns of metadata that we're interested in exploring, rather than all metadata columns to which it is applicable. Here we'll apply this to our unweighted UniFrac distances, using two sample metadata columns, as follows.

```{bash}
qiime diversity beta-group-significance \
  --i-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \
  --m-metadata-file sample-metadata.tsv \
  --m-metadata-column body-site \
  --o-visualization core-metrics-results/unweighted-unifrac-body-site-significance.qzv \
  --p-pairwise

qiime diversity beta-group-significance \
  --i-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \
  --m-metadata-file sample-metadata.tsv \
  --m-metadata-column subject \
  --o-visualization core-metrics-results/unweighted-unifrac-subject-group-significance.qzv \
  --p-pairwise
```

Check [this link](https://view.qiime2.org/visualization/?type=html&src=https%3A%2F%2Fdocs.qiime2.org%2F2023.7%2Fdata%2Ftutorials%2Fmoving-pictures%2Fcore-metrics-results%2Funweighted-unifrac-body-site-significance.qzv) for an example output.

If continuous sample metadata are correlated with sample composition, we can use the `qiime metadata distance-matrix` in combination with `qiime diversity mantel` and `qiime diversity bioenv`commands.

### Linear Mixed Effects

In order to manage the repeated measures, we will use a linear mixed-effects model. In a mixed-effects model, we combine fixed-effects (your typical linear regression coefficients) with random-effects. These random effects are some (ostensibly random) per-group coefficient which minimizes the error within that group. In our situation, we would want our random effect to be the PatientID as we can see each subject has a different baseline for richness (and we have multiple measures for each patient). By making that a random effect, we can more accurately ascribe associations to the fixed effects as we treat each sample as a "draw" from a per-group distribution.

It is called a random effect because the cause of the per-subject deviation from the population intercept is not known. Its source is "random" in the statistical sense. That is randomness is not introduced to the model, but is instead tolerated by it.

There are several ways to create a linear model with random effects, but we will be using a random-intercept, which allows for the per-subject intercept to take on a different average from the population intercept (modeling what we saw in the group-significance plot above).

```{bash}
qiime longitudinal linear-mixed-effects \
  --m-metadata-file sample-metadata.tsv diversity-core-metrics-phylogenetic/observed_features_vector.qza \
  --p-state-column DayRelativeToNearestHCT \
  --p-individual-id-column PatientID \
  --p-metric observed_features \
  --o-visualization visualizations/lme-obs-features-HCT.qzv
```

Here we see a significant association between richness and the bone marrow transplant.

Options:

-   --p-state-column TEXT Metadata column containing state (time) variable information.
-   --p-individual-id-column TEXT Metadata column containing IDs for individual subjects.
-   --p-metric TEXT Dependent variable column name. Must be a column name located in the metadata or feature table files.

We may also be interested in the effect of the auto fecal microbiota transplant. It should be known that these are generally correlated, so choosing one model over the other will require external knowledge.

```{bash}
qiime longitudinal linear-mixed-effects \
  --m-metadata-file sample-metadata.tsv diversity-core-metrics-phylogenetic/observed_features_vector.qza \
  --p-state-column day-relative-to-fmt \
  --p-individual-id-column PatientID \
  --p-metric observed_features \
  --o-visualization visualizations/lme-obs-features-FMT.qzv
```

We also see a downward trend from the FMT. Since the goal of the FMT was to ameliorate the impact of the bone marrow transplant protocol (which involves an extreme course of antibiotics) on gut health, and the timing of the FMT is related to the timing of the marrow transplant, we might deduce that the negative coefficient is primarily related to the bone marrow transplant procedure. (We can't prove this with statistics alone however, in this case, we are using abductive reasoning).

Looking at the log-likelihood, we also note that the HCT result is slightly better than the FMT in accounting for the loss of richness. But only slightly, if we were to perform model testing it may not prove significant.

In any case, we can ask a more targeted question to identify if the FMT was useful in recovering richness.

By adding the autoFmtGroup to our linear model, we can see if there are different slopes for the two groups, based on an interaction term.

```{bash}
qiime longitudinal linear-mixed-effects \
  --m-metadata-file sample-metadata.tsv diversity-core-metrics-phylogenetic/observed_features_vector.qza \
  --p-state-column day-relative-to-fmt \
  --p-group-columns autoFmtGroup \
  --p-individual-id-column PatientID \
  --p-metric observed_features \
  --o-visualization visualizations/lme-obs-features-treatmentVScontrol.qzv
```

Here we see that the autoFmtGroup is not on its own a significant predictor of richness, but its interaction term with Q('day-relative-to-fmt') is. This implies that there are different slopes between these groups, and we note that given the coding of Q('day-relative-to-fmt'):autoFmtGroup\[T.treatment\] we have a positive coefficient which counteracts (to a degree) the negative coefficient of Q('day-relative-to-fmt').

Notice: The slopes of the regression scatterplot in this visualization are not the same fit as our mixed-effects model in the table. They are a naive OLS fit to give a sense of the situation. A proper visualization would be a partial regression plot which can condition on other terms to show some effect in "isolation". This is not currently implemented in QIIME 2.

### Test the above models with a different diversity index, such as Faith's Phylogenetic Diversity

```{bash}
#test group significance 
qiime diversity alpha-group-significance \
  --i-alpha-diversity diversity-core-metrics-phylogenetic/faith_pd_vector.qza \
  --m-metadata-file sample-metadata.tsv \
  --o-visualization visualizations/alpha-group-sig-faith-pd.qzv

#lme
qiime longitudinal linear-mixed-effects \
  --m-metadata-file sample-metadata.tsv diversity-core-metrics-phylogenetic/faith_pd_vector.qza \
  --p-state-column day-relative-to-fmt \
  --p-group-columns autoFmtGroup \
  --p-individual-id-column PatientID \
  --p-metric faith_pd \
  --o-visualization visualizations/lme-faith-pd-treatmentVScontrol.qzv
```

### Beta diversity

Beta diversity is between sample diversity. This is useful for answering the question, how different are these microbial communities?

List of available indices:

-   Jaccard distance (a qualitative measure of community dissimilarity)
-   Bray-Curtis distance (a quantitative measure of community dissimilarity)
-   unweighted UniFrac distance (a qualitative measure of community dissimilarity that incorporates phylogenetic relationships between the features)
-   weighted UniFrac distance (a quantitative measure of community dissimilarity that incorporates phylogenetic relationships between the features)

```{bash}
qiime diversity beta-rarefaction \
  --i-table filtered-table-4.qza \
  --p-metric braycurtis \
  --p-clustering-method nj \
  --p-sampling-depth 10000 \
  --m-metadata-file sample-metadata.tsv \
  --o-visualization visualizations/braycurtis-rarefaction-plot.qzv
```


-   [umap](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8547469/) is an ordination method that can be used in place of PCoA and has been shown to better resolve differences between microbiome samples in ordination plots [@armstrong].
-   Like PCoA, umap operates on distance matrices. We'll compute this on our weighted and unweighted UniFrac distance matrices.

```{bash}
qiime diversity umap \
  --i-distance-matrix diversity-core-metrics-phylogenetic/unweighted_unifrac_distance_matrix.qza \
  --o-umap uu-umap.qza

qiime diversity umap \
  --i-distance-matrix diversity-core-metrics-phylogenetic/weighted_unifrac_distance_matrix.qza \
  --o-umap wu-umap.qza
```

In the next few steps, we'll integrate our unweighted UniFrac umap axis 1 values, and our Faith PD, evenness, and Shannon diversity values, as metadata in visualizations. This will provide a few different ways of interpreting these values.

```{bash}
qiime metadata tabulate \
  --m-input-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --o-visualization expanded-metadata-summ.qzv
```

To see how this information can be used, let's generate another version of our taxonomy barplots that includes these new metadata values.

```{bash}
qiime taxa barplot \
  --i-table filtered-table-4.qza \
  --i-taxonomy taxonomy.qza \
  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --o-visualization visualizations/taxa-bar-plots-2.qzv
```

We'll start by integrating these values as metadata in our ordination plots. We'll also customize these plots in another way: in addition to plotting the ordination axes, we'll add an explicit time axis to these plots. This is often useful for visualization patterns in ordination plots in time series studies. We'll add an axis for week-relative-to-hct.

```{bash}
qiime emperor plot \
  --i-pcoa uu-umap.qza \
  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --p-custom-axes week-relative-to-hct \
  --o-visualization visualizations/uu-umap-emperor-w-time.qzv

qiime emperor plot \
  --i-pcoa wu-umap.qza \
  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --p-custom-axes week-relative-to-hct \
  --o-visualization visualizations/wu-umap-emperor-w-time.qzv

qiime emperor plot \
  --i-pcoa diversity-core-metrics-phylogenetic/unweighted_unifrac_pcoa_results.qza \
  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --p-custom-axes week-relative-to-hct \
  --o-visualization visualizations/uu-pcoa-emperor-w-time.qzv

qiime emperor plot \
  --i-pcoa diversity-core-metrics-phylogenetic/weighted_unifrac_pcoa_results.qza \
  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --p-custom-axes week-relative-to-hct \
  --o-visualization visualizations/wu-pcoa-emperor-w-time.qzv
```

Tip:

QIIME 2's q2-diversity plugin provides visualizations for assessing whether microbiome composition differs across groups of independent samples (for example, individuals with a certain disease state and healthy controls) and for assessing whether differences in microbiome composition are correlated with differences in a continuous variable (for example, subjects' body mass index). These tools assume that all samples are independent of one another, and therefore aren't applicable to the data used in this tutorial where multiple samples are obtained from the same individual. We therefore don't illustrate the use of these visualizations on this data, but you can learn about these approaches and view examples in the Moving Pictures tutorial. The Moving Pictures tutorial contains example data and commands, like this tutorial does, so you can experiment with generating these visualizations on your own.

## Differential abundance testing

ANCOM can be applied to identify features that are differentially abundant (i.e. present in different abundances) across sample groups. As with any bioinformatics method, you should be aware of the assumptions and limitations of ANCOM before using it. We recommend reviewing the [ANCOM paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4450248/) before using this method [@mandal2015].

Differential abundance testing in microbiome analysis is an active area of research. There are two QIIME 2 plugins that can be used for this: q2-gneiss and q2-composition. [The moving pictures tutorial](https://docs.qiime2.org/2023.7/tutorials/moving-pictures/) uses q2-composition, but there is [another tutorial](https://docs.qiime2.org/2023.7/tutorials/gneiss/) which uses gneiss on a different dataset if you are interested in learning more.

ANCOM is implemented in the q2-composition plugin. ANCOM assumes that few (less than about 25%) of the features are changing between groups. If you expect that more features are changing between your groups, you should not use ANCOM as it will be more error-prone (an increase in both Type I and Type II errors is possible). If you for example assume that a lot of features change across sample types/body sites/subjects/etc then ANCOM could be good to use.


## Longitudinal microbiome analysis

### Data transformation

Before applying these analyses, we're going to perform some additional operations on the feature table that will make these analyses run quicker and make the results more interpretable.

First, we are going to use the taxonomic information that we generated earlier to redefine our features as microbial genera. To do this, we group (or collapse) ASV features based on their taxonomic assignments through the genus level. This is achieved using the q2-taxa plugin's collapse action.

```{bash}
qiime taxa collapse \
  --i-table filtered-table-4.qza \
  --i-taxonomy taxonomy.qza \
  --p-level 6 \
  --o-collapsed-table genus-table.qza
```

Then, to focus on the genera that are likely to display the most interesting patterns over time (and to reduce the runtime of the steps that come next), we will perform even more filtering. This time we'll apply prevalence and abudnance based filtering. Specifically, we'll require that a genus's abundance is at least 1% in at least 10% of the samples.

Note: The prevalence-based filtering applied here is fairly stringent. In your own analyses you may want to experiment with relaxed settings of these parameters. Because we want the commands below to run quickly, stringent filtering is helpful for the tutorial.

```{bash}
qiime feature-table filter-features-conditionally \
  --i-table genus-table.qza \
  --p-prevalence 0.1 \
  --p-abundance 0.01 \
  --o-filtered-table filtered-genus-table.qza
```

Finally, we'll convert the counts in our feature table to relative frequencies. This is required for some of the analyses that we're about to perform.

```{bash}
qiime feature-table relative-frequency \
  --i-table filtered-genus-table.qza \
  --o-relative-frequency-table genus-rf-table.qza
```

### Volatility plots

The first plots we'll generate are volatility plots. We'll generate these using two different time variables. First, we'll plot based on week-relative-to-hct.

The volatility visualizer generates interactive line plots that allow us to assess how volatile a dependent variable is over a continuous, independent variable (e.g., time) in one or more groups. See also the [QIIME notes](https://docs.qiime2.org/2023.7/tutorials/longitudinal/)

```{bash}
qiime longitudinal volatility \
  --i-table genus-rf-table.qza \
  --p-state-column week-relative-to-hct \
  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --p-individual-id-column PatientID \
  --p-default-group-column autoFmtGroup \
  --o-visualization visualizations/volatility-plot-1.qzv
```

Next, we'll plot based on week-relative-to-fmt.

```{bash}
qiime longitudinal volatility \
  --i-table genus-rf-table.qza \
  --p-state-column week-relative-to-fmt \
  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --p-individual-id-column PatientID \
  --p-default-group-column autoFmtGroup \
  --o-visualization visualizations/volatility-plot-2.qzv
```

### Feature volatility

The last plots we'll generate in this section will come from a QIIME 2 pipeline called feature-volatility. These use supervised regression to identify features that are most associated with changes over time, and add plotting of those features to a volatility control chart.

Again, we'll generate the same plots but using two different time variables on the x-axes. First, we'll plot based on week-relative-to-hct.

```{bash}
qiime longitudinal feature-volatility \
  --i-table filtered-genus-table.qza \
  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --p-state-column week-relative-to-hct \
  --p-individual-id-column PatientID \
  --output-dir visualizations/longitudinal-feature-volatility
```

Next, we'll plot based on week-relative-to-fmt.

```{bash}
qiime longitudinal feature-volatility \
  --i-table filtered-genus-table.qza \
  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \
  --p-state-column week-relative-to-fmt \
  --p-individual-id-column PatientID \
  --output-dir visualizations/longitudinal-feature-volatility-2
```

Outputs:

1.  volatility-plot contains an interactive feature volatility plot. This is very similar to the plots produced by the volatility visualizer described above, with a couple key differences. First, only features are viewable as "metrics" (plotted on the y-axis). Second, feature metadata (feature importances and descriptive statistics) are plotted as bar charts below the volatility plot. The relative frequencies of different features can be plotted in the volatility chart by either selecting the "metric" selection tool, or by clicking on one of the bars in the bar plot. This makes it convenient to select features for viewing based on importance or other feature metadata. By default, the most important feature is plotted in the volatility plot when the visualization is viewed. Different feature metadata can be selected and sorted using the control panel to the right of the bar charts. Most of these should be self-explanatory, except for "cumulative average change" (the cumulative magnitude of change, both positive and negative, across states, and averaged across samples at each state), and "net average change" (positive and negative "cumulative average change" is summed to determine whether a feature increased or decreased in abundance between baseline and end of study).
2.  accuracy-results display the predictive accuracy of the regression model. This is important to view, as important features are meaningless if the model is inaccurate. See the sample classifier tutorial for more description of regressor accuracy results.
3.  feature-importance contains the importance scores of all features. This is viewable in the feature volatility plot, but this artifact is nonetheless output for convenience. See the sample classifier tutorial for more description of feature importance scores.
4.  filtered-table is a FeatureTable\[RelativeFrequency\] artifact containing only important features. This is output for convenience.
5.  sample-estimator contains the trained sample regressor. This is output for convenience, just in case you plan to regress additional samples. See the sample classifier tutorial for more description of the SampleEstimator type.

## `qiime tools export`: Export data

If you're a veteran microbiome scientist and don't want to use QIIME 2 for your analyses, you can extract your feature table and sequences from the artifact using the export tool. While export only outputs the data, the extract tool allows you to also extract other metadata such as the citations, provenance etc.

Note that this places generically named files (e.g. feature-table.txt) into the output directory, so you may want to immediately rename the files to something more information (or somehow ensure that they stay in their original directory)!

You can also use the handy qiime2R package to import QIIME 2 artifacts directly into R.

## References