[
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Software",
    "section": "",
    "text": "Available software information\nGo to https://scienceparkstudygroup.github.io/software_information/ for information about software that might be useful for bioinformatic data analyses. Please note: This is very much a work in progress and the page will be slowly updated over time.\nIf you want to add additional information you are welcome to do so. For now, feel free to send an email to n.dombrowski@uva.nl with a markdown, quarto or text file with all relevant information and I can integrate this into the webpage. In the future, a “how-to-add-your-own-information” section will be added as well."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Software information",
    "section": "",
    "text": "On this website you can find documentation about software that might be useful for bioinformatic data analyses. Please note: This is very much a work in progress and the page will be slowly updated over time.\nIf you want to add additional information you are welcome to do so. For now, feel free to send an email to n.dombrowski@uva.nl with a markdown, quarto or text file with all relevant information and I can integrate this into the webpage. In the future, a “how-to-add-your-own-information” section will be added as well.\nOn each page, you will find a note if the software is installed on Crunchomics in the introduction. Additionally, each page will give you a brief installation instruction as well as some basic information about using the tool."
  },
  {
    "objectID": "source/ITSx/readme.html",
    "href": "source/ITSx/readme.html",
    "title": "Software information",
    "section": "",
    "text": "“ITSx is an open source software utility to extract the highly variable ITS1 and ITS2 subregions from ITS sequences, which is commonly used as a molecular barcode for e.g. fungi.”\n\nWebsite\nManual\n\nAvailable on Crunchomics: No\n\n\n\nITSx can be installed from scratch but below is the code needed to install the software with mamba (or conda if that is preferred). If you don’t have mamba/conda installed find the correction version for your system here for mamba and here for conda. Examples for setting up either mamba or conda are found in the code cell below.\nIf there is an issue with the mamba/conda installation, the software can also be downloaded with wget https://microbiology.se/sw/ITSx_1.1.3.tar.gz. After the download, decompress the folder and follow the information in the readme.txt. The download also comes with a test.fasta which can be used to test either installation.\nData for testing can also be found here.\n\n\n\n#install conda (run only if not yet installed)\n#adjust the file name based on your system needs\nwget https://repo.anaconda.com/archive/Anaconda3-2023.07-2-Linux-x86_64.sh\n\nbash Anaconda3-2023.07-2-Linux-x86_64.sh\n\n#install mamba (run only if not yet installed)\n#adjust the file name based on your system needs\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\n\nbash Mambaforge-Linux-x86_64.sh\n\n\n\n\n\nmamba create -n fungi_its\nmamba install -n fungi_its -c bioconda itsx\n\n\n\n\n\nmamba install -c bioconda itsx\n\n\n\n\n\n\nRequired input: FASTA format (aligned or unaligned, DNA or RNA)\nGenerated output:\n\none summary file of the entire run\none more detailed table containing the positions in the respective sequences where the ITS subregions were found\none “semi-graphical” representation of hits\none FASTA file of all identified ITS sequences\none FASTA file for the ITS1 and ITS2 regions\nif entries that did not contain any ITS region are found, a list of sequence IDs representing those entries (optional)\n\nUseful arguments (not extensive, check manual for all arguments):\n\n--save_regions: Get all regions of interest, not only ITS1/2\n-E {value}: E-value cutoff (default 1e-5)\n-S {value}: Domain score cutoff (default 0)\n--cpu {value }: Number of cpus to use (default 1)\n--multi_thread {T/F}: Multi-thread the HMMER-search. On (T) by default if the number of CPUs/cores is larger than one (–cpu option > 1), else off (F)\n--preserve {T/F}: If on, ITSx will preserve the sequence headers from the input file instead of replacing them with ITSx headers in the output. Off (F) by default.\n--only_full {T/F}: If true, the output is limited to full-length ITS1 and ITS2 regions only. Off (F) by default.\n--minlen {value} Minimum length the ITS regions must be to be outputted in the concatenated file (see –concat above). Default is zero (0).\n\n\n\n\n\n#activate the right environment (if using environment)\nmamba deactivate\nmamba activate fungi_its\n\n#testrun (adjust path of test.fasta to where ever you downloaded the software)\nmkdir testing\nITSx -i software/ITSx_1.1.3/test.fasta --save_regions all -o testing/ITS_test_v1\n\n#sanity checking\ngrep -c \">\" *fasta\n\n#deactivate environment (if using environment)\nmamba deactivate\n\nRegions extracted from test file (notice how the full fasta ONLY contains sequences with all regions):\n\nITS_test_v1.5_8S.fasta:50\nITS_test_v1.ITS1.fasta:50\nITS_test_v1.ITS2.fasta:50\nITS_test_v1.LSU.fasta:32\nITS_test_v1.SSU.fasta:31\nITS_test_v1.full.fasta:19"
  },
  {
    "objectID": "source/Qiime/qiime_cmi_tutorial.html",
    "href": "source/Qiime/qiime_cmi_tutorial.html",
    "title": "Software",
    "section": "",
    "text": "Notice:\n\nThis tutorial was not written by myself but taken from QIIME tutorial. Additionally, the notes you find here were expended by copying from several spots in the QIIME documentation to explore things.\nThe code was run on my personal computer (Windows, WSL2).\nIf you follow the link for the tutorial, you will see that the tutorial is also available using the Galaxy interface and python API.\n\nOther useful resources to check out:\n\nQIIME 2 view: web-based viewer for .qza and .qzv files\nQIIME forum\nQIIME2 docs. Notice, the tutorial runs on v2021.2, which we will use for now and later update to the newest QIIME version\nQIIME2 Library. Useful to check for new plugins/functionality\nOld QIIME tutorials\nNEW QIIME tutorials\n\n\n\n\n\n\nAll files generated by QIIME 2 are either .qza or .qzv files, and these are simply zip files that store your data alongside some QIIME 2-specific metadata. You can unzip them with unzip xxx.qza\nThe .qza file extension is an abbreviation for QIIME Zipped Artifact, and the .qzv file extension is an abbreviation for QIIME Zipped Visualization. .qza files (which are often simply referred to as artifacts) are intermediary files in a QIIME 2 analysis, usually containing raw data of some sort.\nData produced by QIIME 2 exist as QIIME 2 artifacts. A QIIME 2 artifact contains data and metadata. The metadata describes things about the data, such as its type, format, and how it was generated (provenance). A QIIME 2 artifact typically has the .qza file extension when stored in a file. Since QIIME 2 works with artifacts instead of data files (e.g. FASTA files), you must create a QIIME 2 artifact by importing data.\nVisualizations are another type of data generated by QIIME 2. When written to disk, visualization files typically have the .qzv file extension. Visualizations contain similar types of metadata as QIIME 2 artifacts, including provenance information. Similar to QIIME 2 artifacts, visualizations are standalone information that can be archived or shared with collaborators. Use https://view.qiime2.org to easily view QIIME 2 artifacts and visualizations files (generally .qza and .qzv files) without requiring a QIIME installation.\nPlugins are software packages that can be developed by anyone and define actions, which are steps in an analysis workflow. The QIIME 2 team has developed several plugins for an initial end-to-end microbiome analysis pipeline, but third-party developers are encouraged to create their own plugins to provide additional analyses.\nQIIME actions:\n\nA method, i.e.alpha-phylogenetic, accepts some combination of QIIME 2 artifacts and parameters as input, and produces one or more QIIME 2 artifacts (qza file) as output.\nA visualizer is similar to a method in that it accepts some combination of QIIME 2 artifacts and parameters as input and generate qzv files. In contrast to a method, a visualizer produces exactly one visualization as output. An example of a QIIME 2 visualizer is the beta-group-significance action in the q2-diversity plugin.\nA pipeline can generate one or more .qza and/or .qzv as output. Pipelines are special in that they’re a type of action that can call other actions. They are often used by developers to define simplify common workflows so they can be run by users in a single step. For example, the core-metrics-phylogenetic action in the q2-diversity plugin is a Pipeline that runs both alpha-phylogenetic and beta-phylogenetic, as well as several other actions, in a single command.\n\nTypes used in QIIME 2:\n\nFile type: the format of a file used to store some data. For example, newick is a file type that is used for storing phylogenetic trees.\nData type: refer to how data is represented in a computer’s memory (i.e., RAM) while it’s actively in use.\nEvery artifact generated by QIIME 2 has a semantic type associated with it. This is a representation of the meaning of the data. For example, two semantic types used in QIIME 2 are Phylogeny[Rooted] and Phylogeny[Unrooted], which are used to represent rooted and unrooted trees, respectively. QIIME 2 methods will describe what semantic types they take as input(s), and what semantic types they generate as output(s).\n\n\n\n\n\n\nFind out more also here.\n\nMetadata:\n\nSample metadata may include technical details, such as the DNA barcodes that were used for each sample in a multiplexed sequencing run, or descriptions of the samples, such as which subject, time point, and body site each sample came from\nFeature metadata is often a feature annotation, such as the taxonomy assigned to an amplicon sequence variant (ASV).\nQIIME 2 does not place restrictions on what types of metadata are expected to be present; there are no enforced “metadata standards”.\nthe MIxS and MIMARKS standards [1] provide recommendations for microbiome studies and may be helpful in determining what information to collect in your study. If you plan to deposit your data in a data archive (e.g. ENA or Qiita), it is also important to determine the types of metadata expected by that resource.\nIn QIIME 2, we always refer to these files as metadata files, but they are conceptually the same thing as QIIME 1 mapping files. QIIME 2 metadata files are backwards-compatible with QIIME 1 mapping files, meaning that you can use existing QIIME 1 mapping files in QIIME 2 without needing to make modifications to the file.\n\n\n\n\n\nUsually provided as TSV file (.tsv or .txt file extension) that provides data in form of rows and columns\nFirst row = non-comment, non-empty column headers containing a unique identifier for each metadata entry\nRows whose first cell begins with the pound sign (#) are interpreted as comments and may appear anywhere in the file. Comment rows are ignored by QIIME 2 and are for informational purposes only. Inline comments (i.e., comments that begin part-way through a row or at the end of a row) are not supported.\nEmpty rows (e.g. blank lines or rows consisting solely of empty cells) may appear anywhere in the file and are ignored.\nColumn 1: identifier (ID) column. This column defines the sample or feature IDs associated with your study. It is not recommended to mix sample and feature IDs in a single metadata file; keep sample and feature metadata stored in separate files. The ID column name (also referred to as the ID column header) must be:\n\nCase-insenitive (i.e., uppercase or lowercase, or a mixing of the two, is allowed): id, sampleid, sample id, sample-id, featureid feature id, feature-id\nIDs may consist of any Unicode characters, with the exception that IDs must not start with the pound sign (#), as those rows would be interpreted as comments and ignored.\nIDs cannot be empty (i.e. they must consist of at least one character).\nIDs must be unique (exact string matching is performed to detect duplicates).\nAt least one ID must be present in the file.\nIDs cannot be any of the reserved ID headers listed above.\n\nThe ID column is the first column in the metadata file, and can optionally be followed by additional columns defining metadata associated with each sample or feature ID. Metadata files are not required to have additional metadata columns, so a file containing only an ID column is a valid QIIME 2 metadata file.\nThe contents of a metadata file following the ID column and header row (excluding comments and empty lines) are referred to as the metadata values. A single metadata value, defined by an (ID, column) pair, is referred to as a cell. The following rules apply to metadata values and cells:\n\nMay consist of any Unicode characters.\nEmpty cells represent missing data. Other values such as NA are not interpreted as missing data; only the empty cell is recognized as “missing”. Note that cells consisting solely of whitespace characters are also interpreted as missing data\nIf any cell in the metadata contains leading or trailing whitespace characters (e.g. spaces, tabs), those characters will be ignored when the file is loaded.\n\n\nRecommendations for identifiers:\n\nIdentifiers should be 36 characters long or less.\nIdentifiers should contain only ASCII alphanumeric characters (i.e. in the range of [a-z], [A-Z], or [0-9]), the period (.) character, or the dash (-) character.\nNote that some bioinformatics tools may have more restrictive requirements on identifiers than the recommendations that are outlined here. For example, Illumina sample sheet identifiers cannot have . characters, while we do include those in our set of recommended characters\n[cual-id] (https://github.com/johnchase/cual-id) can be used to help create identifiers and the associated paper also includes a discussion on how to choose identifiers [2].\n\nColumn types:\n\nQIIME 2 currently supports categorical and numeric metadata columns and will automatically attempt to infer the type of each metadata column\nQIIME 2 supports an optional comment directive to allow users to explicitly state a column’s type.\nThe comment directive must appear directly below the header row. The value in the ID column in this row must be #q2:types to indicate the row is a comment directive. Subsequent cells in this row may contain the values categorical or numeric (both case-insensitive). The empty cell is also supported if you do not wish to assign a type to a column\n\nMetadata validation:\n\nQIIME 2 will automatically validate a metadata file anytime it is used. Loading your metadata in QIIME 2 will typically present only a single error at a time, which can make identifying and resolving validation issues cumbersome, especially if there are many issues with the metadata.\nSample and feature metadata files stored in Google Sheets can additionally be validated using Keemei [3]\n\n\n\n\n\nThis tutorial focuses on data reused a Compilation of longitudinal microbiota data and hospitalome from hematopoietic cell transplantation patients [4]\n\n\n\n\n\n#find out what plugins are installed\nqiime --help\n\n#get help for a plugin of interest\nqiime diversity --help\n\n#get help for an action in a plugin\nqiime diversity alpha-phylogenetic --help\n\n\n\n\n\n\n\nRun this if needed. If you are not using mamba yet, replace mamba with conda to use this as an alternative installer.\n\nwget https://data.qiime2.org/distro/core/qiime2-2023.7-py38-linux-conda.yml\nmamba env create -n qiime2-2023.7 --file qiime2-2023.7-py38-linux-conda.yml\n#mamba activate qiime2-2023.7\n\n\n\n\n\n#set wdir\nwdir=\"/mnt/c/Users/ndmic/WorkingDir/UvA/Tutorials/QIIME/qiime_cmi_tutorial\"\ncd $wdir \n\n#activate QIIME environment \nmamba activate qiime2-2023.7\n\n\n\n\n\n\nmkdir data\nmkdir visualizations\n\n#download metadata table\nwget \\\n  -O 'sample-metadata.tsv' \\\n  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/020-tutorial-upstream/020-metadata/sample-metadata.tsv'\n\n#prepare metadata for qiime view \nqiime metadata tabulate \\\n  --m-input-file sample-metadata.tsv \\\n  --o-visualization visualizations/metadata-summ-1.qzv\n\n#download sequencing data (already demultiplexed)\nwget \\\n  -O 'data_to_import.zip' \\\n  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/020-tutorial-upstream/030-importing/data_to_import.zip'\n\nunzip -d data_to_import data_to_import.zip\n\nrm data_to_import.zip\n\n\n\n\n\n#import data into qiime\nqiime tools import \\\n  --type 'SampleData[PairedEndSequencesWithQuality]' \\\n  --input-format CasavaOneEightSingleLanePerSampleDirFmt \\\n  --input-path data_to_import \\\n  --output-path demultiplexed-sequences.qza\n\n#generate a summary of the imported data\nqiime demux summarize \\\n  --i-data demultiplexed-sequences.qza \\\n  --o-visualization visualizations/demultiplexed-sequences-summ.qzv\n\nqiime demux: supports demultiplexing of single-end and paired-end sequence reads and visualization of sequence quality information.\n\n\n\nIf you have reads from multiple samples in the same file, you’ll need to demultiplex your sequences.\nIf your barcodes are still in your sequences, you can use functions from the cutadapt plugin. The cutadapt demux-single method looks for barcode sequences at the beginning of your reads (5’ end) with a certain error tolerance, removes them, and returns sequence data separated by each sample. The QIIME 2 forum has a tutorial on various functions available in cutadapt, including demultiplexing. You can learn more about how cutadapt works under the hood by reading their documentation.\nNote: Currently q2-demux and q2-cutadapt do not support demultiplexing dual-barcoded paired-end sequences, but only can demultiplex with barcodes in the forward reads. So for the time being, this type of demultiplexing needs to be done outside of QIIME 2 using other tools, for example bcl2fastq.\nNotice: This is not applicable for this tutorial and you only will find some relevant notes here.\nThere are two plugins to check out:\n\nq2-demux\ncutadapt\n\n\n\n\nWhether or not you need to merge reads depends on how you plan to cluster or denoise your sequences into amplicon sequence variants (ASVs) or operational taxonomic units (OTUs). If you plan to use deblur or OTU clustering methods next, join your sequences now. If you plan to use dada2 to denoise your sequences, do not merge — dada2 performs read merging automatically after denoising each sequence.\nIf you need to merge your reads, you can use the QIIME 2 q2-vsearch plugin with the merge-pairs method.\nNotice: This is not applicable for this tutorial and you only will find some relevant notes here.\n\n\n\nIf your data contains any non-biological sequences (e.g. primers, sequencing adapters, PCR spacers, etc), you should remove these.\nThe q2-cutadapt plugin has comprehensive methods for removing non-biological sequences from paired-end or single-end data.\nIf you’re going to use DADA2 to denoise your sequences, you can remove biological sequences at the same time as you call the denoising function. All of DADA2’s denoise fuctions have some sort of –p-trim parameter you can specify to remove base pairs from the 5’ end of your reads. (Deblur does not have this functionality yet.)\n\n\n\nThe names for these steps are very descriptive:\n\nWe denoise our sequences to remove and/or correct noisy reads.\nWe dereplicate our sequences to reduce repetition and file size/memory requirements in downstream steps.\nWe cluster sequences to collapse similar sequences (e.g., those that are ≥ 97% similar to each other) into single replicate sequences. This process, also known as OTU picking, was once a common procedure, used to simultaneously dereplicate but also perform a sort of quick-and-dirty denoising procedure (to capture stochastic sequencing and PCR errors, which should be rare and similar to more abundant centroid sequences). Use denoising methods instead if you can.\n\nThe denoising methods currently available in QIIME 2 include DADA2 and Deblur. Note that deblur (and also vsearch dereplicate-sequences) should be preceded by basic quality-score-based filtering, but this is unnecessary for dada2. Both Deblur and DADA2 contain internal chimera checking methods and abundance filtering, so additional filtering should not be necessary following these methods.\nTo put it simply, these methods filter out noisy sequences, correct errors in marginal sequences (in the case of DADA2), remove chimeric sequences, remove singletons, join denoised paired-end reads (in the case of DADA2), and then dereplicate those sequences.\n\n\nThe final products of all denoising and clustering methods/workflows are a FeatureTable[Frequency] (feature table) artifact and a FeatureData[Sequence] (representative sequences) artifact. These are two of the most important artifacts in an amplicon sequencing workflow, and are used for many downstream analyses.\nMany operations on these tables can be performed with q2-feature-table.\nWant to see which sequences are associated with each feature ID? Use qiime metadata tabulate with your FeatureData[Sequence] artifact as input.\n\n\n\nQuality control or denoising of the sequence data will be performed with DADA2 [5]. DADA2 is an model-based approach for correcting amplicon errors without constructing OTUs. Can be applied to every gene of interest and is not limited to the 16S.\nThe DADA2 algorithm makes use of a parametric error model (err) and every amplicon dataset has a different set of error rates. The learnErrors method learns this error model from the data, by alternating estimation of the error rates and inference of sample composition until they converge on a jointly consistent solution. As in many machine-learning problems, the algorithm must begin with an initial guess, for which the maximum possible error rates in this data are used (the error rates if only the most abundant sequence is correct and all the rest are errors).\nAlso check out this tutorial for using DADA2. One important parameter to check is truncLen to trim low quality read ends. Also check out this paper discussing quality filtering [6].\nIn QIIME the denoise_paired action in the q2-dada2 plugin. This performs quality filtering, chimera checking, and paired- end read joining.\nThe denoise_paired action requires a few parameters that you’ll set based on the sequence quality score plots that you previously generated in the summary of the demultiplex reads. You should review those plots and identify where the quality begins to decrease, and use that information to set the trunc_len_* parameters. You’ll set that for both the forward and reverse reads using the trunc_len_f and trunc_len_r parameters, respectively. If you notice a region of lower quality in the beginning of the forward and/or reverse reads, you can optionally trim bases from the beginning of the reads using the trim_left_f and trim_left_r parameters for the forward and reverse reads, respectively. Your reads must still overlap after truncation in order to merge them later!\nSome thoughts on this:\n\nReviewing the data we notice that the twenty-fifth percentile quality score drops below 30 at position 204 in the forward reads and 205 in the reverse reads. We chose to use those values for the required truncation lengths. This truncates the 3’/5’ end of the of the input sequences. Reads that are shorter than this value will be discarded. After this parameter is applied there must still be at least a 12 nucleotide overlap between the forward and reverse reads.\nSince the first base of the reverse reads is slightly lower than those that follow, I choose to trim that first base in the reverse reads, but apply no trimming to the forward reads. This trimming is probably unnecessary here, but is useful here for illustrating how this works.\nFigaro is a tool to automatically choose the trunc_len\nChimeric sequences are identified if they can be exactly reconstructed by combining a left-segment and a right-segment from two more abundant “parent” sequences. Most of your reads should remain after chimera removal (it is not uncommon for a majority of sequence variants to be removed though). If most of your reads were removed as chimeric, upstream processing may need to be revisited. In almost all cases this is caused by primer sequences with ambiguous nucleotides that were not removed prior to running DADA2\n\nDesired overlap length\n\nOften between 10 and 20 for most applications.\nDADA2 often recommends 20\nRemember: longer overlaps means more 3’ end must be kept at a cost of decreased overall sequence quality\n\nOther parameters:\n\n--p-max-ee-f/r {number}: Forward reads with number of expected errors higher than this value will be discarded. [default: 2.0]. If you want to speed up downstream computation, consider tightening maxEE. If too few reads are passing the filter, consider relaxing maxEE, perhaps especially on the reverse reads (eg. maxEE=c(2,5))\n--p-trunc-q {integeer}: Reads are truncated at the first instance of a quality score less than or equal to this value. If the resulting read is then shorter than trunc-len-for trunc-len-r (depending on the direction of the read) it is discarded. [default: 2]\n--p-min-overlap {INTEGER}: The minimum length of the overlap required for merging the forward and reverse reads. [default: 12]\n--p-pooling-method {TEXT Choices(‘independent’, ‘pseudo’)}: he method used to pool samples for denoising. By default, the dada function processes each sample independently. However, pooling information across samples can increase sensitivity to sequence variants that may be present at very low frequencies in multiple samples. “independent”: Samples are denoised indpendently. “pseudo”: The pseudo-pooling method is used to approximate pooling of samples. In short, samples are denoised independently once, ASVs detected in at least 2 samples are recorded, and samples are denoised independently a second time, but this time with prior knowledge of the recorded ASVs and thus higher sensitivity to those ASVs. [default: ‘independent’]\n--p-chimera-method {TEXT Choices(‘consensus’, ‘none’, ‘pooled’)}: The method used to remove chimeras. “none”: No chimera removal is performed. “pooled”: All reads are pooled prior to chimera detection. “consensus”: Chimeras are detected in samples individually, and sequences found chimeric in a sufficient fraction of samples are removed. [default: ‘consensus’]\n--p-n-threads {INTEGER}: default 1\n\nOutputs:\n\nThe feature table describes which amplicon sequence variants (ASVs) were observed in which samples, and how many times each ASV was observed in each sample.\nThe feature data in this case is the sequence that defines each ASV. Generate and explore the summaries of each of these files.\nSanity check: in stats-dada2 check that outside of filtering, there should no step in which a majority of reads are lost. If a majority of reads failed to merge, you may need to revisit the truncLen parameter used in the filtering step and make sure that the truncated reads span your amplicon. If a majority of reads were removed as chimeric, you may need to revisit the removal of primers, as the ambiguous nucleotides in unremoved primers interfere with chimera identification\nSequences that are much longer or shorter than expected may be the result of non-specific priming. You could consider removing those sequences from the asv table.\n\n\n#denoise data\nqiime dada2 denoise-paired \\\n  --i-demultiplexed-seqs demultiplexed-sequences.qza \\\n  --p-trunc-len-f 204 \\\n  --p-trim-left-r 1 \\\n  --p-trunc-len-r 205 \\\n  --o-representative-sequences asv-sequences-0.qza \\\n  --o-table feature-table-0.qza \\\n  --o-denoising-stats dada2-stats.qza\n\n#generate summaries\nqiime feature-table summarize \\\n  --i-table feature-table-0.qza \\\n  --m-sample-metadata-file sample-metadata.tsv \\\n  --o-visualization visualizations/feature-table-0-summ.qzv\n\nqiime feature-table tabulate-seqs \\\n  --i-data asv-sequences-0.qza \\\n  --o-visualization visualizations/asv-sequences-0-summ.qzv\n\nqiime metadata tabulate \\\n  --m-input-file dada2-stats.qza \\\n  --o-visualization visualizations/stats-dada2.qzv\n\nOutputs:\n\nASV table,\nthe representative sequences,\nstatistics on the procedure\n\n\n\n\n\nWe’ll next obtain a much larger feature table representing all of the samples included in the study dataset. These would take too much time to denoise in this course, so we’ll start with the feature table, sequences, and metadata provided by the authors and filter to samples that we’ll use for our analyses.\nA full description can be foun on the QIIME website\n\n#cleanup first dataset\nmkdir upstream_tutorial\nmv *qza upstream_tutorial/\n\n#get the data\nwget \\\n  -O 'feature-table.qza' \\\n  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/030-tutorial-downstream/010-filtering/feature-table.qza'\n\nwget \\\n  -O 'rep-seqs.qza' \\\n  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/030-tutorial-downstream/010-filtering/rep-seqs.qza'\n\n#summarize table\nqiime feature-table summarize \\\n  --i-table feature-table.qza \\\n  --m-sample-metadata-file sample-metadata.tsv \\\n  --o-visualization visualizations/feature-table-summ.qzv\n\nqiime feature-table tabulate-seqs \\\n  --i-data rep-seqs.qza \\\n  --o-visualization visualizations/rep-seqs-summ.qzv\n\nOutput explanation:\n\nA feature is essentially any unit of observation, e.g., an OTU, a sequence variant, a gene, a metabolite, etc, and a feature table is a matrix of sample X feature abundances (the number of times each feature was observed in each sample).\nminimum frequency is 5342 - if you click the “Interactive Sample Detail” tab and scroll to the bottom, you will see that the sample with the lowest feature frequency has 5342 observations. Similarly, the sample with the highest frequency of features has 193491 total observations - meaning that many/most features were seen more than once.\nmean frequency of features (881)? Does it mean that one feature is found in average 881 times throughout all the samples\n\n\n\n\n#filtering\nqiime feature-table filter-samples \\\n  --i-table feature-table.qza \\\n  --m-metadata-file sample-metadata.tsv \\\n  --p-where 'autoFmtGroup IS NOT NULL' \\\n  --o-filtered-table autofmt-table.qza\n\n#summarize\nqiime feature-table summarize \\\n  --i-table autofmt-table.qza \\\n  --m-sample-metadata-file sample-metadata.tsv \\\n  --o-visualization visualizations/autofmt-table-summ.qzv\n\n#filter time window\nqiime feature-table filter-samples \\\n  --i-table autofmt-table.qza \\\n  --m-metadata-file sample-metadata.tsv \\\n  --p-where 'DayRelativeToNearestHCT BETWEEN -10 AND 70' \\\n  --o-filtered-table filtered-table-1.qza\n\n#filter features from the feature table if they don’t occur in at least two samples\n#done to reduce runtime (so optional)\nqiime feature-table filter-features \\\n  --i-table filtered-table-1.qza \\\n  --p-min-samples 2 \\\n  --o-filtered-table filtered-table-2.qza\n\n#summarize\nqiime feature-table summarize \\\n  --i-table filtered-table-2.qza \\\n  --m-sample-metadata-file sample-metadata.tsv \\\n  --o-visualization visualizations/filtered-table-2-summ.qzv\n\nOptions for qiime feature-table filter-samples:\n\nAny features with a frequency of zero after sample filtering will also be removed.\n--p-min-frequency {INTEGER} The minimum total frequency that a sample must have to be retained. [default: 0]\n--p-max-frequency {INTEGER} The maximum total frequency that a sample can have to be retained. If no value is provided this will default to infinity (i.e., no maximum frequency filter will be applied). [optional]\n--p-min-features {INTEGER} The minimum number of features that a sample must have to be retained. [default: 0]\n--p-max-features {INTEGER}\n--m-metadata-file METADATA… (multiple Sample metadata used with where parameter when arguments will selecting samples to retain, or with exclude-ids when be merged) selecting samples to discard. [optional]\n--p-where {TEXT} SQLite WHERE clause specifying sample metadata criteria that must be met to be included in the filtered feature table. If not provided, all samples in metadata that are also in the feature table will be retained. [optional] --p-exclude-ids / --p-no-exclude-ids If true, the samples selected by metadata or where parameters will be excluded from the filtered table instead of being retained. [default: False] --p-filter-empty-features / --p-no-filter-empty-features If true, features which are not present in any retained samples are dropped. [default: True]\n--p-min-samples {number}: filter features from a table contingent on the number of samples they’re observed in.\n--p-min-features {number}: filter samples that contain only a few features\n\nWe can also also filter tables by lists:\n\n#create imaginary list of ids to keep\necho L1S8 >> samples-to-keep.tsv\n\n#filter \nqiime feature-table filter-samples \\\n  --i-table table.qza \\\n  --m-metadata-file samples-to-keep.tsv \\\n  --o-filtered-table id-filtered-table.qza\n\nSome examples using where:\n\n–p-where “[subject]=‘subject-1’”\n\n–p-where “[body-site] IN (‘left palm’, ‘right palm’)”\n\n–p-where “[subject]=‘subject-1’ AND [body-site]=‘gut’”\n\n–p-where “[body-site]=‘gut’ OR [reported-antibiotic-usage]=‘Yes’”\n\n–p-where “[subject]=‘subject-1’ AND NOT [body-site]=‘gut’”\n\n\n\n\n\n\nqiime feature-table filter-seqs \\\n  --i-data rep-seqs.qza \\\n  --i-table filtered-table-2.qza \\\n  --o-filtered-data filtered-sequences-1.qza\n\n\n\n\n\nTo identify the organisms in a sample it is usually not enough using the closest alignment — because other sequences that are equally close matches or nearly as close may have different taxonomic annotations. So we use taxonomy classifiers to determine the closest taxonomic affiliation with some degree of confidence or consensus (which may not be a species name if one cannot be predicted with certainty!), based on alignment, k-mer frequencies, etc.\nq2-feature-classifier contains three different classification methods: - classify-consensus-blast and classify-consensus-vsearch are both alignment-based methods that find a consensus assignment across N top hits. These methods take reference database FeatureData[Taxonomy] and FeatureData[Sequence] files directly, and do not need to be pre-trained - Machine-learning-based classification methods are available through classify-sklearn, and theoretically can apply any of the classification methods available in scikit-learn. These classifiers must be trained, e.g., to learn which features best distinguish each taxonomic group, adding an additional step to the classification process. Classifier training is reference database- and marker-gene-specific and only needs to happen once per marker-gene/reference database combination; that classifier may then be re-used as many times as you like without needing to re-train! - Most users do not even need to follow that tutorial and perform that training step, because the lovely QIIME 2 developers provide several pre-trained classifiers for public use.\nIn general classify-sklearn with a Naive Bayes classifier can slightly outperform other methods we’ve tested based on several criteria for classification of 16S rRNA gene and fungal ITS sequences. It can be more difficult and frustrating for some users, however, since it requires that additional training step. That training step can be memory intensive, becoming a barrier for some users who are unable to use the pre-trained classifiers.\nIn the example below we use a pre-trained Naive Bayes taxonomic classifier. This particular classifier was trained on the Greengenes 13-8 database, where sequences were trimmed to represent only the region between the 515F / 806R primers.\nCheck out the Qiime info page for other classifiers.\nNotes:\n\nTaxonomic classifiers perform best when they are trained based on your specific sample preparation and sequencing parameters, including the primers that were used for amplification and the length of your sequence reads. Therefore in general you should follow the instructions in Training feature classifiers with q2-feature-classifier to train your own taxonomic classifiers (for example, from the marker gene reference databases below).\nGreengenes2 has succeeded Greengenes 13_8\nThe Silva classifiers provided here include species-level taxonomy. While Silva annotations do include species, Silva does not curate the species-level taxonomy so this information may be unreliable.\nCheck out this study to learn more about QIIMEs feature classifier [7].\nCheck out this study discussing reproducible sequence taxonomy reference database management [8].\nCheck out this study about incorporating environment-specific taxonomic abundance information in taxonomic classifiers [9].\n\n\n\n\n#get classifier\nwget \\\n  -O 'gg-13-8-99-nb-classifier.qza' \\\n  'https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/data/030-tutorial-downstream/020-taxonomy/gg-13-8-99-nb-classifier.qza'\n\n#assign taxonomic info to ASV sequences\nqiime feature-classifier classify-sklearn \\\n  --i-classifier gg-13-8-99-nb-classifier.qza \\\n  --i-reads filtered-sequences-1.qza \\\n  --o-classification taxonomy.qza\n\n#generate summary\nqiime metadata tabulate \\\n  --m-input-file taxonomy.qza \\\n  --o-visualization visualizations/taxonomy.qzv\n\n\n\n\nA common step in 16S analysis is to remove sequences from an analysis that aren’t assigned to a phylum. In a human microbiome study such as this, these may for example represent reads of human genome sequence that were unintentionally sequences.\nHere, we:\n\nspecify with the include paramater that an annotation must contain the text p__, which in the Greengenes taxonomy is the prefix for all phylum-level taxonomy assignments. Taxonomic labels that don’t contain p__ therefore were maximally assigned to the domain (i.e., kingdom) level.\nremove features that are annotated with p__; (which means that no named phylum was assigned to the feature), as well as annotations containing Chloroplast or Mitochondria (i.e., organelle 16S sequences).\n\n\nqiime taxa filter-table \\\n  --i-table filtered-table-2.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --p-mode contains \\\n  --p-include p__ \\\n  --p-exclude 'p__;,Chloroplast,Mitochondria' \\\n  --o-filtered-table filtered-table-3.qza\n\nOther options:\nFilter by taxonomy:\n\nqiime taxa filter-table \\\n  --i-table table.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --p-exclude mitochondria \\\n  --o-filtered-table table-no-mitochondria.qza\n\nqiime taxa filter-table \\\n  --i-table table.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --p-exclude mitochondria,chloroplast \\\n  --o-filtered-table table-no-mitochondria-no-chloroplast.qza\n\nqiime taxa filter-table \\\n  --i-table table.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --p-include p__ \\\n  --o-filtered-table table-with-phyla.qza\n\nqiime taxa filter-table \\\n  --i-table table.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --p-include p__ \\\n  --p-exclude mitochondria,chloroplast \\\n  --o-filtered-table table-with-phyla-no-mitochondria-no-chloroplast.qza\n\nqiime taxa filter-table \\\n  --i-table table.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --p-mode exact \\\n  --p-exclude \"k__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rickettsiales; f__mitochondria\" \\\n  --o-filtered-table table-no-mitochondria-exact.qza\n\nWe can also filter our sequences:\n\nqiime taxa filter-seqs \\\n  --i-sequences sequences.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --p-include p__ \\\n  --p-exclude mitochondria,chloroplast \\\n  --o-filtered-sequences sequences-with-phyla-no-mitochondria-no-chloroplast.qza\n\n\n\n\nYou may have noticed when looking at feature table summaries earlier that some of the samples contained very few ASV sequences. These often represent samples which didn’t amplify or sequence well, and when we start visualizing our data low numbers of sequences can cause misleading results, because the observed composition of the sample may not be reflective of the sample’s actual composition. For this reason it can be helpful to exclude samples with low ASV sequence counts from our samples. Here, we’ll filter out samples from which we have obtained fewer than 10,000 sequences.\n\nqiime feature-table filter-samples \\\n  --i-table filtered-table-3.qza \\\n  --p-min-frequency 10000 \\\n  --o-filtered-table filtered-table-4.qza\n\n#summarize data\nqiime feature-table summarize \\\n  --i-table filtered-table-4.qza \\\n  --m-sample-metadata-file sample-metadata.tsv \\\n  --o-visualization visualizations/filtered-table-4-summ.qzv\n\n\n\n\n\nqiime feature-table filter-seqs \\\n  --i-data rep-seqs.qza \\\n  --i-table filtered-table-4.qza \\\n  --o-filtered-data filtered-sequences-2.qza\n\n\n\n\n\n\nqiime taxa barplot \\\n  --i-table filtered-table-4.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --m-metadata-file sample-metadata.tsv \\\n  --o-visualization visualizations/taxa-bar-plots-1.qzv\n\nNotice: We can also generate heatmaps with feature-table heatmap\n\n\n\n\n\nOne advantage of pipelines is that they combine ordered sets of commonly used commands, into one condensed simple command. To keep these “convenience” pipelines easy to use, it is quite common to only expose a few options to the user. That is, most of the commands executed via pipelines are often configured to use default option settings. However, options that are deemed important enough for the user to consider setting, are made available. The options exposed via a given pipeline will largely depend upon what it is doing. Pipelines are also a great way for new users to get started, as it helps to lay a foundation of good practices in setting up standard operating procedures.\nRather than run one or more of the following QIIME 2 commands listed below:\nqiime alignment mafft ...\n\nqiime alignment mask ...\n\nqiime phylogeny fasttree ...\n\nqiime phylogeny midpoint-root ...\nWe can make use of the pipeline align-to-tree-mafft-fasttree to automate the above four steps in one go. Here is the description taken from the pipeline help doc:\nMore details can be found in the QIIME docs.\nIn general there are two approaches:\n\nA reference-based fragment insertion approach. Which, is likely the ideal choice. Especially, if your reference phylogeny (and associated representative sequences) encompass neighboring relatives of which your sequences can be reliably inserted. Any sequences that do not match well enough to the reference are not inserted. For example, this approach may not work well if your data contain sequences that are not well represented within your reference phylogeny (e.g. missing clades, etc.). For more information, check out these great fragment insertion examples.\nA de novo approach. Marker genes that can be globally aligned across divergent taxa, are usually amenable to sequence alignment and phylogenetic investigation through this approach. Be mindful of the length of your sequences when constructing a de novo phylogeny, short reads many not have enough phylogenetic information to capture a meaningful phylogeny.\n\n\n\n\n\nqiime phylogeny align-to-tree-mafft-fasttree \\\n  --i-sequences filtered-sequences-2.qza \\\n  --output-dir phylogeny-align-to-tree-mafft-fasttree\n\nThe final unrooted phylogenetic tree will be used for analyses that we perform next - specifically for computing phylogenetically aware diversity metrics. While output artifacts will be available for each of these steps, we’ll only use the rooted phylogenetic tree later.\nNotice:\n\nFor an easy and direct way to view your tree.qza files, upload them to iTOL. Here, you can interactively view and manipulate your phylogeny. Even better, while viewing the tree topology in “Normal mode”, you can drag and drop your associated alignment.qza (the one you used to build the phylogeny) or a relevent taxonomy.qza file onto the iTOL tree visualization. This will allow you to directly view the sequence alignment or taxonomy alongside the phylogeny\n\nMethods in qiime phylogeny:\n\nalign-to-tree-mafft-iqtree\niqtree Construct a phylogenetic tree with IQ-TREE.\niqtree-ultrafast-bootstrap Construct a phylogenetic tree with IQ-TREE with bootstrap supports.\nmidpoint-root Midpoint root an unrooted phylogenetic tree.\nrobinson-foulds Calculate Robinson-Foulds distance between phylogenetic trees.\n\n\n\n\nBefore running iq-tree check out:\n\nqiime alignment mafft\nqiime alignment mask\n\nExample to run the iqtree command with default settings and automatic model selection (MFP) is like so:\n\nqiime phylogeny iqtree \\\n  --i-alignment masked-aligned-rep-seqs.qza \\\n  --o-tree iqt-tree.qza \\\n  --verbose\n\nExample running iq-tree with single branch testing:\nSingle branch tests are commonly used as an alternative to the bootstrapping approach we’ve discussed above, as they are substantially faster and often recommended when constructing large phylogenies (e.g. >10,000 taxa).\n\nqiime phylogeny iqtree \\\n  --i-alignment masked-aligned-rep-seqs.qza \\\n  --p-alrt 1000 \\\n  --p-abayes \\\n  --p-lbp 1000 \\\n  --p-substitution-model 'GTR+I+G' \\\n  --o-tree iqt-sbt-tree.qza \\\n  --verbose\n\nIQ-tree settings:\nThere are quite a few adjustable parameters available for iqtree that can be modified improve searches through “tree space” and prevent the search algorithms from getting stuck in local optima.\nOne particular best practice to aid in this regard, is to adjust the following parameters: –p-perturb-nni-strength and –p-stop-iter (each respectively maps to the -pers and -nstop flags of iqtree ).\nIn brief, the larger the value for NNI (nearest-neighbor interchange) perturbation, the larger the jumps in “tree space”. This value should be set high enough to allow the search algorithm to avoid being trapped in local optima, but not to high that the search is haphazardly jumping around “tree space”. One way of assessing this, is to do a few short trial runs using the --verbose flag. If you see that the likelihood values are jumping around to much, then lowering the value for --p-perturb-nni-strength may be warranted.\nAs for the stopping criteria, i.e. --p-stop-iter, the higher this value, the more thorough your search in “tree space”. Be aware, increasing this value may also increase the run time. That is, the search will continue until it has sampled a number of trees, say 100 (default), without finding a better scoring tree. If a better tree is found, then the counter resets, and the search continues.\nThese two parameters deserve special consideration when a given data set contains many short sequences, quite common for microbiome survey data. We can modify our original command to include these extra parameters with the recommended modifications for short sequences, i.e. a lower value for perturbation strength (shorter reads do not contain as much phylogenetic information, thus we should limit how far we jump around in “tree space”) and a larger number of stop iterations.\n\nqiime phylogeny iqtree \\\n  --i-alignment masked-aligned-rep-seqs.qza \\\n  --p-perturb-nni-strength 0.2 \\\n  --p-stop-iter 200 \\\n  --p-n-cores 1 \\\n  --o-tree iqt-nnisi-fast-tree.qza \\\n  --verbose\n\niqtree-ultrafast-bootstrap:\nwe can also use IQ-TREE to evaluate how well our splits / bipartitions are supported within our phylogeny via the ultrafast bootstrap algorithm. Below, we’ll apply the plugin’s ultrafast bootstrap command: automatic model selection (MFP), perform 1000 bootstrap replicates (minimum required), set the same generally suggested parameters for constructing a phylogeny from short sequences, and automatically determine the optimal number of CPU cores to use:\n\nqiime phylogeny iqtree-ultrafast-bootstrap \\\n  --i-alignment masked-aligned-rep-seqs.qza \\\n  --p-perturb-nni-strength 0.2 \\\n  --p-stop-iter 200 \\\n  --p-n-cores 1 \\\n  --o-tree iqt-nnisi-bootstrap-tree.qza \\\n  --verbose\n\n\n\n\n\n\n\nNotice: Notes copied taken from here\nFeature tables are composed of sparse and compositional data [10]. Measuring microbial diversity using 16S rRNA sequencing is dependent on sequencing depth. By chance, a sample that is more deeply sequenced is more likely to exhibit greater diversity than a sample with a low sequencing depth.\nRarefaction is the process of subsampling reads without replacement to a defined sequencing depth, thereby creating a standardized library size across samples. Any sample with a total read count less than the defined sequencing depth used to rarefy will be discarded. Post-rarefaction all samples will have the same read depth. How do we determine the magic sequencing depth at which to rarefy? We typically use an alpha rarefaction curve.\nAs the sequencing depth increases, you recover more and more of the diversity observed in the data. At a certain point (read depth), diversity will stabilize, meaning the diversity in the data has been fully captured. This point of stabilization will result in the diversity measure of interest plateauing.\nNotice:\n\nYou may want to skip rarefaction if library sizes are fairly even. Rarefaction is more beneficial when there is a greater than ~10x difference in library size [11].\nRarefying is generally applied only to diversity analyses, and many of the methods in QIIME 2 will use plugin specific normalization methods\n\nSome literature on the debate:\n\nWaste not, want not: why rarefying microbiome data is inadmissible [12]\nNormalization and microbial differential abundance strategies depend upon data characteristics [11]\n\n\n\n\nAlpha diversity is within sample diversity. When exploring alpha diversity, we are interested in the distribution of microbes within a sample or metadata category. This distribution not only includes the number of different organisms (richness) but also how evenly distributed these organisms are in terms of abundance (evenness).\nRichness: High richness equals more ASVs or more phylogenetically dissimilar ASVs in the case of Faith’s PD. Diversity increases as richness and evenness increase. Evenness: High values suggest more equal numbers between species.\nHere is a description of the different metrices we can use. And check here for a comparison of indices.\nList of indices:\n\nShannon’s diversity index (a quantitative measure of community richness)\nObserved Features (a qualitative measure of community richness)\nFaith’s Phylogenetic Diversity (a qualitative measure of community richness that incorporates phylogenetic relationships between the features)\nEvenness (or Pielou’s Evenness; a measure of community evenness)\n\nAn important parameter that needs to be provided to this script is --p-sampling-depth, which is the even sampling (i.e. rarefaction) depth. Because most diversity metrics are sensitive to different sampling depths across different samples, this script will randomly subsample the counts from each sample to the value provided for this parameter. For example, if you provide --p-sampling-depth 500, this step will subsample the counts in each sample without replacement so that each sample in the resulting table has a total count of 500. If the total count for any sample(s) are smaller than this value, those samples will be dropped from the diversity analysis.\n\nqiime diversity alpha-rarefaction \\\n  --i-table filtered-table-4.qza \\\n  --p-metrics shannon \\\n  --m-metadata-file sample-metadata.tsv \\\n  --p-max-depth 33000 \\\n  --o-visualization visualizations/shannon-rarefaction-plot.qzv\n\nNote: The value that you provide for --p-max-depth should be determined by reviewing the “Frequency per sample” information presented in the table.qzv file that was created above. In general, choosing a value that is somewhere around the median frequency seems to work well, but you may want to increase that value if the lines in the resulting rarefaction plot don’t appear to be leveling out, or decrease that value if you seem to be losing many of your samples due to low total frequencies closer to the minimum sampling depth than the maximum sampling depth.\nInclude phylo:\n\nqiime diversity alpha-rarefaction \\\n  --i-table filtered-table-4.qza \\\n  --i-phylogeny phylogeny-align-to-tree-mafft-fasttree/rooted_tree.qza \\\n  --p-metrics faith_pd \\\n  --m-metadata-file sample-metadata.tsv \\\n  --p-max-depth 33000 \\\n  --o-visualization visualizations/faith-rarefaction-plot.qzv\n\nGenerate different metrics at the same time:\n\nqiime diversity alpha-rarefaction \\\n  --i-table filtered-table-4.qza \\\n  --i-phylogeny phylogeny-align-to-tree-mafft-fasttree/rooted_tree.qza \\\n  --m-metadata-file sample-metadata.tsv \\\n  --p-max-depth 33000 \\\n  --o-visualization visualizations/alpha-rarefaction-plot.qzv \n\nWe can use this plot in combination with our feature table summary to decide at which depth we would like to rarefy. We need to choose a sequencing depth at which the diveristy in most of the samples has been captured and most of the samples have been retained.\nChoosing this value is tricky. We recommend making your choice by reviewing the information presented in the feature table summary file. Choose a value that is as high as possible (so you retain more sequences per sample) while excluding as few samples as possible.\n\n\n\n\ncore-metrics-phylogeneticrequires your feature table, your rooted phylogenetic tree, and your sample metadata as input. It additionally requires that you provide the sampling depth that this analysis will be performed at. Determining what value to provide for this parameter is often one of the most confusing steps of an analysis for users, and we therefore have devoted time to discussing this in the lectures and in the previous chapter. In the interest of retaining as many of the samples as possible, we’ll set our sampling depth to 10,000 for this analysis.\n\nqiime diversity core-metrics-phylogenetic \\\n  --i-phylogeny phylogeny-align-to-tree-mafft-fasttree/rooted_tree.qza \\\n  --i-table filtered-table-4.qza \\\n  --p-sampling-depth 10000 \\\n  --m-metadata-file sample-metadata.tsv \\\n  --output-dir diversity-core-metrics-phylogenetic\n\n\n\nThe code below generates Alpha Diversity Boxplots as well as statistics based on the observed features. It allows us to explore the microbial composition of the samples in the context of the sample metadata.\n\nqiime diversity alpha-group-significance \\\n  --i-alpha-diversity diversity-core-metrics-phylogenetic/observed_features_vector.qza \\\n  --m-metadata-file sample-metadata.tsv \\\n  --o-visualization visualizations/alpha-group-sig-obs-feats.qzv\n\nThe first thing to notice is the high variability in each individual’s richness (PatientID). The centers and spreads of the individual distributions are likely to obscure other effects, so we will want to keep this in mind. Additionally, we have repeated measures of each individual, so we are violating independence assumptions when looking at other categories. (Kruskal-Wallis is a non-parameteric test, but like most tests, still requires samples to be independent.)\n\n\n\nIf continuous sample metadata columns (e.g., days-since-experiment-start) are correlated with alpha diversity, we can test for those associations here. If you’re interested in performing those tests (for this data set, or for others), you can use the qiime diversity alpha-correlation command.\nWe can also analyze sample composition in the context of categorical metadata using PERMANOVA using the beta-group-significance command. The code below was taken from another test but would allow to test whether distances between samples within a group, such as samples from the same body site (e.g., gut), are more similar to each other then they are to samples from the other groups (e.g., tongue, left palm, and right palm). If you call this command with the --p-pairwise parameter, as we’ll do here, it will also perform pairwise tests that will allow you to determine which specific pairs of groups (e.g., tongue and gut) differ from one another, if any. This command can be slow to run, especially when passing --p-pairwise, since it is based on permutation tests. So, unlike the previous commands, we’ll run beta-group-significance on specific columns of metadata that we’re interested in exploring, rather than all metadata columns to which it is applicable. Here we’ll apply this to our unweighted UniFrac distances, using two sample metadata columns, as follows.\n\nqiime diversity beta-group-significance \\\n  --i-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \\\n  --m-metadata-file sample-metadata.tsv \\\n  --m-metadata-column body-site \\\n  --o-visualization core-metrics-results/unweighted-unifrac-body-site-significance.qzv \\\n  --p-pairwise\n\nqiime diversity beta-group-significance \\\n  --i-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \\\n  --m-metadata-file sample-metadata.tsv \\\n  --m-metadata-column subject \\\n  --o-visualization core-metrics-results/unweighted-unifrac-subject-group-significance.qzv \\\n  --p-pairwise\n\nCheck this link for an example output.\nIf continuous sample metadata are correlated with sample composition, we can use the qiime metadata distance-matrix in combination with qiime diversity mantel and qiime diversity bioenvcommands.\n\n\n\nIn order to manage the repeated measures, we will use a linear mixed-effects model. In a mixed-effects model, we combine fixed-effects (your typical linear regression coefficients) with random-effects. These random effects are some (ostensibly random) per-group coefficient which minimizes the error within that group. In our situation, we would want our random effect to be the PatientID as we can see each subject has a different baseline for richness (and we have multiple measures for each patient). By making that a random effect, we can more accurately ascribe associations to the fixed effects as we treat each sample as a “draw” from a per-group distribution.\nIt is called a random effect because the cause of the per-subject deviation from the population intercept is not known. Its source is “random” in the statistical sense. That is randomness is not introduced to the model, but is instead tolerated by it.\nThere are several ways to create a linear model with random effects, but we will be using a random-intercept, which allows for the per-subject intercept to take on a different average from the population intercept (modeling what we saw in the group-significance plot above).\n\nqiime longitudinal linear-mixed-effects \\\n  --m-metadata-file sample-metadata.tsv diversity-core-metrics-phylogenetic/observed_features_vector.qza \\\n  --p-state-column DayRelativeToNearestHCT \\\n  --p-individual-id-column PatientID \\\n  --p-metric observed_features \\\n  --o-visualization visualizations/lme-obs-features-HCT.qzv\n\nHere we see a significant association between richness and the bone marrow transplant.\nOptions:\n\n–p-state-column TEXT Metadata column containing state (time) variable information.\n–p-individual-id-column TEXT Metadata column containing IDs for individual subjects.\n–p-metric TEXT Dependent variable column name. Must be a column name located in the metadata or feature table files.\n\nWe may also be interested in the effect of the auto fecal microbiota transplant. It should be known that these are generally correlated, so choosing one model over the other will require external knowledge.\n\nqiime longitudinal linear-mixed-effects \\\n  --m-metadata-file sample-metadata.tsv diversity-core-metrics-phylogenetic/observed_features_vector.qza \\\n  --p-state-column day-relative-to-fmt \\\n  --p-individual-id-column PatientID \\\n  --p-metric observed_features \\\n  --o-visualization visualizations/lme-obs-features-FMT.qzv\n\nWe also see a downward trend from the FMT. Since the goal of the FMT was to ameliorate the impact of the bone marrow transplant protocol (which involves an extreme course of antibiotics) on gut health, and the timing of the FMT is related to the timing of the marrow transplant, we might deduce that the negative coefficient is primarily related to the bone marrow transplant procedure. (We can’t prove this with statistics alone however, in this case, we are using abductive reasoning).\nLooking at the log-likelihood, we also note that the HCT result is slightly better than the FMT in accounting for the loss of richness. But only slightly, if we were to perform model testing it may not prove significant.\nIn any case, we can ask a more targeted question to identify if the FMT was useful in recovering richness.\nBy adding the autoFmtGroup to our linear model, we can see if there are different slopes for the two groups, based on an interaction term.\n\nqiime longitudinal linear-mixed-effects \\\n  --m-metadata-file sample-metadata.tsv diversity-core-metrics-phylogenetic/observed_features_vector.qza \\\n  --p-state-column day-relative-to-fmt \\\n  --p-group-columns autoFmtGroup \\\n  --p-individual-id-column PatientID \\\n  --p-metric observed_features \\\n  --o-visualization visualizations/lme-obs-features-treatmentVScontrol.qzv\n\nHere we see that the autoFmtGroup is not on its own a significant predictor of richness, but its interaction term with Q(‘day-relative-to-fmt’) is. This implies that there are different slopes between these groups, and we note that given the coding of Q(‘day-relative-to-fmt’):autoFmtGroup[T.treatment] we have a positive coefficient which counteracts (to a degree) the negative coefficient of Q(‘day-relative-to-fmt’).\nNotice: The slopes of the regression scatterplot in this visualization are not the same fit as our mixed-effects model in the table. They are a naive OLS fit to give a sense of the situation. A proper visualization would be a partial regression plot which can condition on other terms to show some effect in “isolation”. This is not currently implemented in QIIME 2.\n\n\n\n\n#test group significance \nqiime diversity alpha-group-significance \\\n  --i-alpha-diversity diversity-core-metrics-phylogenetic/faith_pd_vector.qza \\\n  --m-metadata-file sample-metadata.tsv \\\n  --o-visualization visualizations/alpha-group-sig-faith-pd.qzv\n\n#lme\nqiime longitudinal linear-mixed-effects \\\n  --m-metadata-file sample-metadata.tsv diversity-core-metrics-phylogenetic/faith_pd_vector.qza \\\n  --p-state-column day-relative-to-fmt \\\n  --p-group-columns autoFmtGroup \\\n  --p-individual-id-column PatientID \\\n  --p-metric faith_pd \\\n  --o-visualization visualizations/lme-faith-pd-treatmentVScontrol.qzv\n\n\n\n\nBeta diversity is between sample diversity. This is useful for answering the question, how different are these microbial communities?\nList of available indices:\n\nJaccard distance (a qualitative measure of community dissimilarity)\nBray-Curtis distance (a quantitative measure of community dissimilarity)\nunweighted UniFrac distance (a qualitative measure of community dissimilarity that incorporates phylogenetic relationships between the features)\nweighted UniFrac distance (a quantitative measure of community dissimilarity that incorporates phylogenetic relationships between the features)\n\n\nqiime diversity beta-rarefaction \\\n  --i-table filtered-table-4.qza \\\n  --p-metric braycurtis \\\n  --p-clustering-method nj \\\n  --p-sampling-depth 10000 \\\n  --m-metadata-file sample-metadata.tsv \\\n  --o-visualization visualizations/braycurtis-rarefaction-plot.qzv\n\n\numap is an ordination method that can be used in place of PCoA and has been shown to better resolve differences between microbiome samples in ordination plots [13].\nLike PCoA, umap operates on distance matrices. We’ll compute this on our weighted and unweighted UniFrac distance matrices.\n\n\nqiime diversity umap \\\n  --i-distance-matrix diversity-core-metrics-phylogenetic/unweighted_unifrac_distance_matrix.qza \\\n  --o-umap uu-umap.qza\n\nqiime diversity umap \\\n  --i-distance-matrix diversity-core-metrics-phylogenetic/weighted_unifrac_distance_matrix.qza \\\n  --o-umap wu-umap.qza\n\nIn the next few steps, we’ll integrate our unweighted UniFrac umap axis 1 values, and our Faith PD, evenness, and Shannon diversity values, as metadata in visualizations. This will provide a few different ways of interpreting these values.\n\nqiime metadata tabulate \\\n  --m-input-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --o-visualization expanded-metadata-summ.qzv\n\nTo see how this information can be used, let’s generate another version of our taxonomy barplots that includes these new metadata values.\n\nqiime taxa barplot \\\n  --i-table filtered-table-4.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --o-visualization visualizations/taxa-bar-plots-2.qzv\n\nWe’ll start by integrating these values as metadata in our ordination plots. We’ll also customize these plots in another way: in addition to plotting the ordination axes, we’ll add an explicit time axis to these plots. This is often useful for visualization patterns in ordination plots in time series studies. We’ll add an axis for week-relative-to-hct.\n\nqiime emperor plot \\\n  --i-pcoa uu-umap.qza \\\n  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --p-custom-axes week-relative-to-hct \\\n  --o-visualization visualizations/uu-umap-emperor-w-time.qzv\n\nqiime emperor plot \\\n  --i-pcoa wu-umap.qza \\\n  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --p-custom-axes week-relative-to-hct \\\n  --o-visualization visualizations/wu-umap-emperor-w-time.qzv\n\nqiime emperor plot \\\n  --i-pcoa diversity-core-metrics-phylogenetic/unweighted_unifrac_pcoa_results.qza \\\n  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --p-custom-axes week-relative-to-hct \\\n  --o-visualization visualizations/uu-pcoa-emperor-w-time.qzv\n\nqiime emperor plot \\\n  --i-pcoa diversity-core-metrics-phylogenetic/weighted_unifrac_pcoa_results.qza \\\n  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --p-custom-axes week-relative-to-hct \\\n  --o-visualization visualizations/wu-pcoa-emperor-w-time.qzv\n\nTip:\nQIIME 2’s q2-diversity plugin provides visualizations for assessing whether microbiome composition differs across groups of independent samples (for example, individuals with a certain disease state and healthy controls) and for assessing whether differences in microbiome composition are correlated with differences in a continuous variable (for example, subjects’ body mass index). These tools assume that all samples are independent of one another, and therefore aren’t applicable to the data used in this tutorial where multiple samples are obtained from the same individual. We therefore don’t illustrate the use of these visualizations on this data, but you can learn about these approaches and view examples in the Moving Pictures tutorial. The Moving Pictures tutorial contains example data and commands, like this tutorial does, so you can experiment with generating these visualizations on your own.\n\n\n\n\nANCOM can be applied to identify features that are differentially abundant (i.e. present in different abundances) across sample groups. As with any bioinformatics method, you should be aware of the assumptions and limitations of ANCOM before using it. We recommend reviewing the ANCOM paper before using this method [14].\nDifferential abundance testing in microbiome analysis is an active area of research. There are two QIIME 2 plugins that can be used for this: q2-gneiss and q2-composition. The moving pictures tutorial uses q2-composition, but there is another tutorial which uses gneiss on a different dataset if you are interested in learning more.\nANCOM is implemented in the q2-composition plugin. ANCOM assumes that few (less than about 25%) of the features are changing between groups. If you expect that more features are changing between your groups, you should not use ANCOM as it will be more error-prone (an increase in both Type I and Type II errors is possible). If you for example assume that a lot of features change across sample types/body sites/subjects/etc then ANCOM could be good to use.\n\n\n\n\n\nBefore applying these analyses, we’re going to perform some additional operations on the feature table that will make these analyses run quicker and make the results more interpretable.\nFirst, we are going to use the taxonomic information that we generated earlier to redefine our features as microbial genera. To do this, we group (or collapse) ASV features based on their taxonomic assignments through the genus level. This is achieved using the q2-taxa plugin’s collapse action.\n\nqiime taxa collapse \\\n  --i-table filtered-table-4.qza \\\n  --i-taxonomy taxonomy.qza \\\n  --p-level 6 \\\n  --o-collapsed-table genus-table.qza\n\nThen, to focus on the genera that are likely to display the most interesting patterns over time (and to reduce the runtime of the steps that come next), we will perform even more filtering. This time we’ll apply prevalence and abudnance based filtering. Specifically, we’ll require that a genus’s abundance is at least 1% in at least 10% of the samples.\nNote: The prevalence-based filtering applied here is fairly stringent. In your own analyses you may want to experiment with relaxed settings of these parameters. Because we want the commands below to run quickly, stringent filtering is helpful for the tutorial.\n\nqiime feature-table filter-features-conditionally \\\n  --i-table genus-table.qza \\\n  --p-prevalence 0.1 \\\n  --p-abundance 0.01 \\\n  --o-filtered-table filtered-genus-table.qza\n\nFinally, we’ll convert the counts in our feature table to relative frequencies. This is required for some of the analyses that we’re about to perform.\n\nqiime feature-table relative-frequency \\\n  --i-table filtered-genus-table.qza \\\n  --o-relative-frequency-table genus-rf-table.qza\n\n\n\n\nThe first plots we’ll generate are volatility plots. We’ll generate these using two different time variables. First, we’ll plot based on week-relative-to-hct.\nThe volatility visualizer generates interactive line plots that allow us to assess how volatile a dependent variable is over a continuous, independent variable (e.g., time) in one or more groups. See also the QIIME notes\n\nqiime longitudinal volatility \\\n  --i-table genus-rf-table.qza \\\n  --p-state-column week-relative-to-hct \\\n  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --p-individual-id-column PatientID \\\n  --p-default-group-column autoFmtGroup \\\n  --o-visualization visualizations/volatility-plot-1.qzv\n\nNext, we’ll plot based on week-relative-to-fmt.\n\nqiime longitudinal volatility \\\n  --i-table genus-rf-table.qza \\\n  --p-state-column week-relative-to-fmt \\\n  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --p-individual-id-column PatientID \\\n  --p-default-group-column autoFmtGroup \\\n  --o-visualization visualizations/volatility-plot-2.qzv\n\n\n\n\nThe last plots we’ll generate in this section will come from a QIIME 2 pipeline called feature-volatility. These use supervised regression to identify features that are most associated with changes over time, and add plotting of those features to a volatility control chart.\nAgain, we’ll generate the same plots but using two different time variables on the x-axes. First, we’ll plot based on week-relative-to-hct.\n\nqiime longitudinal feature-volatility \\\n  --i-table filtered-genus-table.qza \\\n  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --p-state-column week-relative-to-hct \\\n  --p-individual-id-column PatientID \\\n  --output-dir visualizations/longitudinal-feature-volatility\n\nNext, we’ll plot based on week-relative-to-fmt.\n\nqiime longitudinal feature-volatility \\\n  --i-table filtered-genus-table.qza \\\n  --m-metadata-file sample-metadata.tsv uu-umap.qza diversity-core-metrics-phylogenetic/faith_pd_vector.qza diversity-core-metrics-phylogenetic/evenness_vector.qza diversity-core-metrics-phylogenetic/shannon_vector.qza \\\n  --p-state-column week-relative-to-fmt \\\n  --p-individual-id-column PatientID \\\n  --output-dir visualizations/longitudinal-feature-volatility-2\n\nOutputs:\n\nvolatility-plot contains an interactive feature volatility plot. This is very similar to the plots produced by the volatility visualizer described above, with a couple key differences. First, only features are viewable as “metrics” (plotted on the y-axis). Second, feature metadata (feature importances and descriptive statistics) are plotted as bar charts below the volatility plot. The relative frequencies of different features can be plotted in the volatility chart by either selecting the “metric” selection tool, or by clicking on one of the bars in the bar plot. This makes it convenient to select features for viewing based on importance or other feature metadata. By default, the most important feature is plotted in the volatility plot when the visualization is viewed. Different feature metadata can be selected and sorted using the control panel to the right of the bar charts. Most of these should be self-explanatory, except for “cumulative average change” (the cumulative magnitude of change, both positive and negative, across states, and averaged across samples at each state), and “net average change” (positive and negative “cumulative average change” is summed to determine whether a feature increased or decreased in abundance between baseline and end of study).\naccuracy-results display the predictive accuracy of the regression model. This is important to view, as important features are meaningless if the model is inaccurate. See the sample classifier tutorial for more description of regressor accuracy results.\nfeature-importance contains the importance scores of all features. This is viewable in the feature volatility plot, but this artifact is nonetheless output for convenience. See the sample classifier tutorial for more description of feature importance scores.\nfiltered-table is a FeatureTable[RelativeFrequency] artifact containing only important features. This is output for convenience.\nsample-estimator contains the trained sample regressor. This is output for convenience, just in case you plan to regress additional samples. See the sample classifier tutorial for more description of the SampleEstimator type.\n\n\n\n\n\nIf you’re a veteran microbiome scientist and don’t want to use QIIME 2 for your analyses, you can extract your feature table and sequences from the artifact using the export tool. While export only outputs the data, the extract tool allows you to also extract other metadata such as the citations, provenance etc.\nNote that this places generically named files (e.g. feature-table.txt) into the output directory, so you may want to immediately rename the files to something more information (or somehow ensure that they stay in their original directory)!\nYou can also use the handy qiime2R package to import QIIME 2 artifacts directly into R."
  },
  {
    "objectID": "source/cli/readme.html",
    "href": "source/cli/readme.html",
    "title": "Software information",
    "section": "",
    "text": "The command line interface (cli) is not a software but nevertheless useful for bioinformaticians since it is a text-based user interface used to run programs, manage computer files and interact with the computer.\nYou can use cli as follows (installation instructions tba):\n\nMac: Use the terminal tool (easy to find with spotlight)\nLinux: Use xterm or konsole\nWindows: Use putty, mobaxterm orwindows subsystem for linux (WSL)\n\nIf you want to use Crunchomics, the Genomics Compute Environment for SILS and IBED please check out this documentation.\nIf you are completely unfamiliar with using the command line check out:\n\nAn older session on using the command line. Will be updated to work on Crunchomics in the future\nA tutorial on using AWK, an excellent command line tool for filtering tables, extracting patterns, etc… If you want to follow this tutorial then you can download the required input files from here"
  },
  {
    "objectID": "source/Qiime/readme.html",
    "href": "source/Qiime/readme.html",
    "title": "Software information",
    "section": "",
    "text": "QIIME 2 is a platform for microbial community analysis such as 16S amplicon analysis. The QIIME 2 website comes with a wealth of documentation and tutorials that are worthwhile to check out before running QIIME 2 on your own data:\n\nInstallation instructions\nThe QIIME 2 documentation.\nThe cancer microbiome tutorial\nq2book a very detailed, but still unfinished, tutorial on QIIME 2."
  },
  {
    "objectID": "source/R/readme.html",
    "href": "source/R/readme.html",
    "title": "Using R",
    "section": "",
    "text": "R is a language and environment for statistical computing and graphics and is useful to analyse computational data.\nSome useful information to get started:\n\nInstallation guide for R and RStudio\nAn R cookbook including some example files\nTutorial on data manipulation with dplyr\nTutorial on data visualization with ggplot2"
  },
  {
    "objectID": "source/metagenomics/readme.html",
    "href": "source/metagenomics/readme.html",
    "title": "Software information",
    "section": "",
    "text": "Past workshop materials\nMetagenomics is the study of genetic material recovered directly from environmental or other samples using sequencing technologies. Below you find some tutorials explaining how to work with sequencing data, assemble metagenome-assembled genomes (MAGs) from this sequencing data and how to analyse these MAGS. Notice: These tutorials where not developed at UvA and will be updated in the future but will nevertheless give a good starting point in these kind of analyses.\n\nAssembling a metagenome\nGenomic binning\nAnnotating microbial genomes\nHow to do phylogenetic analyses"
  },
  {
    "objectID": "index.html#general",
    "href": "index.html#general",
    "title": "Software",
    "section": "General",
    "text": "General\nOn this website you can find documentation about software that might be useful for bioinformatic data analyses. Please note: This is very much a work in progress and the page will be slowly updated over time.\nIf you want to add additional information you are welcome to do so. For now, feel free to send an email to n.dombrowski@uva.nl with a markdown, quarto or text file with all relevant information and I can integrate this into the webpage. In the future, a “how-to-add-your-own-information” section will be added as well.\nOn each page, you will find a note if the software is installed on Crunchomics in the introduction. Additionally, each page will give you a brief installation instruction as well as some basic information about using the tool."
  }
]